# -*- coding: utf-8 -*-
"""SlitFedAlzheimer(FedProx).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S-9LpUN71AKSX7ui3B1R8hcAI1QVlvp9
"""

!pip install torchmetrics

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchmetrics
import torchvision
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.models as models
from torch.utils.data import DataLoader, Dataset, Subset
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import confusion_matrix
import numpy as np
import random
import math
import copy
import time
import matplotlib.pyplot as plt
import seaborn as sns

SEED = 1234
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
if torch.cuda.is_available():
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    print(f"Usando GPU: {torch.cuda.get_device_name(0)}")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
data_path = '/content/drive/MyDrive/ADNI'

class RandomNoise(object):
    """Adiciona ruído gaussiano a uma imagem."""
    def __init__(self, p=0.5, mean=0., std=0.1):
        self.p = p
        self.mean = mean
        self.std = std

    def __call__(self, tensor):
        if random.random() < self.p:
            noise = torch.randn(tensor.size()) * self.std + self.mean
            return tensor + noise
        return tensor

    def __repr__(self):
        return self.__class__.__name__ + f'(p={self.p}, mean={self.mean}, std={self.std})'

class CustomDataset(Dataset):
    """Wrapper para aplicar transformações a um Subset."""
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform

    def __getitem__(self, index):
        image, label = self.subset[index]
        if self.transform:
            image = self.transform(image)
        return image, label

    def __len__(self):
        return len(self.subset)

class DenseNet169_client_side(nn.Module):
    """Parte do modelo que roda no cliente."""
    def __init__(self):
        super().__init__()
        dnet = models.densenet169(weights=models.DenseNet169_Weights.DEFAULT)
        # Congela as camadas iniciais para fine-tuning
        for name, param in dnet.features.named_parameters():
            if name.startswith(("conv0", "norm0", "relu0", "pool0")):
                param.requires_grad = False
        self.features = nn.Sequential(
            dnet.features.conv0, dnet.features.norm0, dnet.features.relu0,
            dnet.features.pool0, dnet.features.denseblock1, dnet.features.transition1,
            dnet.features.denseblock2, dnet.features.transition2,
        )

    def forward(self, x):
        return self.features(x)

class DenseNet169_server_side(nn.Module):
    """Parte do modelo que roda no servidor."""
    def __init__(self, num_classes=3):
        super().__init__()
        dnet = models.densenet169(weights=models.DenseNet169_Weights.DEFAULT)
        self.features = nn.Sequential(
            dnet.features.denseblock3, dnet.features.transition3,
            dnet.features.denseblock4, dnet.features.norm5,
            nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)),
        )
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            nn.Linear(1664, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        return self.classifier(x)

class EarlyStopping:
    """Interrompe o treinamento se a perda de validação não melhorar."""
    def __init__(self, patience=7, verbose=False, delta=0, save_path='checkpoint.pt'):
        self.patience, self.verbose, self.delta, self.save_path = patience, verbose, delta, save_path
        self.counter, self.best_score, self.early_stop, self.val_loss_min = 0, None, False, np.Inf

    def __call__(self, val_loss, models):
        net_glob_client, net_glob_server = models
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, net_glob_client, net_glob_server)
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.verbose: print(f'EarlyStopping counter: {self.counter}/{self.patience}')
            if self.counter >= self.patience: self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, net_glob_client, net_glob_server)
            self.counter = 0

    def save_checkpoint(self, val_loss, net_glob_client, net_glob_server):
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model to {self.save_path}')
        torch.save({
            'net_glob_client_state_dict': net_glob_client.state_dict(),
            'net_glob_server_state_dict': net_glob_server.state_dict(),
        }, self.save_path)
        self.val_loss_min = val_loss

class DatasetSplit(Dataset):
    """Um dataset que pega uma fatia de um dataset maior."""
    def __init__(self, dataset, indices, transform=None):
        self.dataset = dataset
        self.indices = list(indices)
        self.transform = transform

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        real_idx = self.indices[idx]
        image, label = self.dataset[real_idx] # Acessa o dataset original
        if self.transform:
             # O dataset original já é um CustomDataset, que aplica a transform.
             # Para evitar dupla aplicação, acessamos o subset interno.
            raw_image, raw_label = self.dataset.subset.dataset[real_idx]
            image = self.transform(raw_image)
            return image, raw_label
        return image, label

class Client(object):
    """Define o comportamento de um cliente usando a lógica FedProx."""
    def __init__(self, net_client_model, idx, lr, device, mu, idxs=None, idxs_test=None):
        self.idx = idx
        self.device = device
        self.lr = lr
        self.local_ep = 1
        self.mu = mu  # <--- MUDANÇA: Armazena o parâmetro mu

        self.train_dataset = CustomDataset(Subset(full_dataset, list(idxs)), transform=train_transform)
        self.test_dataset = CustomDataset(Subset(full_dataset, list(idxs_test)), transform=test_transform)

        self.ldr_train = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)
        self.ldr_test = DataLoader(self.test_dataset, batch_size=batch_size, shuffle=False)

    def train(self, net):
        net.train()
        net.to(self.device)

        # Salva os pesos do modelo global recebido no início da rodada
        global_weights = copy.deepcopy(list(net.parameters()))

        optimizer_client = torch.optim.Adam(net.parameters(), lr=self.lr)

        for iter_ep in range(self.local_ep):
            len_batch = len(self.ldr_train)
            for batch_idx, (images, labels) in enumerate(self.ldr_train):
                images, labels = images.to(self.device), labels.to(self.device)

                optimizer_client.zero_grad()

                # Forward pass para a parte do cliente
                fx = net(images)
                client_fx = fx.clone().detach().requires_grad_(True)

                # Comunicação com o servidor (aqui a lógica não muda)
                dfx = train_server(client_fx, labels, iter_ep, self.local_ep, self.idx, len_batch, optimizer=optimizers_server[self.idx])

                # <--- MUDANÇA: Cálculo da Perda FedProx ---

                # 1. Primeiro, fazemos o backward pass do gradiente do servidor
                fx.backward(dfx)

                # 2. Em seguida, calculamos o termo proximal
                # A perda original (CrossEntropy) já foi calculada no servidor e seu gradiente propagado para o cliente
                # Agora adicionamos o gradiente do termo proximal
                prox_term = 0.0
                # Compara cada peso local atual com o peso global inicial
                for local_w, global_w in zip(net.parameters(), global_weights):
                    prox_term += torch.pow(torch.norm(local_w - global_w), 2)

                # Adiciona o termo proximal à perda total (implicitamente, adicionando seu gradiente)
                prox_loss = (self.mu / 2) * prox_term
                prox_loss.backward()

                # 3. Finalmente, atualizamos os pesos
                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)
                optimizer_client.step()

        return net.state_dict()

    def evaluate(self, net, ell):
        # A lógica de avaliação não muda
        net.eval()
        net.to(device)
        with torch.no_grad():
            len_batch = len(self.ldr_test)
            for batch_idx, (images, labels) in enumerate(self.ldr_test):
                images, labels = images.to(self.device), labels.to(self.device)
                fx = net(images)
                evaluate_server(fx, labels, self.idx, len_batch, ell)

class CombinedModel(nn.Module):
    """Combina o modelo do cliente e do servidor para avaliação final."""
    def __init__(self, client_model, server_model):
        super(CombinedModel, self).__init__()
        self.client_model = client_model
        self.server_model = server_model
    def forward(self, x):
        x = self.client_model(x)
        x = self.server_model(x)
        return x

def FedProx(w):
    """Agregação de pesos pelo algoritmo Federated Averaging."""
    w_avg = copy.deepcopy(w[0])
    for k in w_avg.keys():
        for i in range(1, len(w)):
            w_avg[k] += w[i][k]
        w_avg[k] = torch.div(w_avg[k], len(w))
    return w_avg

def calculate_metrics(fx, y, num_classes=3):
    """Calcula um conjunto de métricas de classificação."""
    preds = fx.argmax(dim=1)
    accuracy = torchmetrics.functional.accuracy(preds, y, task='multiclass', num_classes=num_classes)
    precision = torchmetrics.functional.precision(preds, y, average='macro', task='multiclass', num_classes=num_classes)
    recall = torchmetrics.functional.recall(preds, y, average='macro', task='multiclass', num_classes=num_classes)
    f1 = torchmetrics.functional.f1_score(preds, y, average='macro', task='multiclass', num_classes=num_classes)
    auc = torchmetrics.functional.auroc(F.softmax(fx, dim=1), y, task='multiclass', num_classes=num_classes)
    return accuracy, precision, recall, f1, auc

def train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch, optimizer):
    """Lógica de treinamento que roda no servidor."""
    global net_model_server, criterion, device, batch_acc_train, batch_loss_train
    global batch_precision_train, batch_recall_train, batch_auc_train, l_epoch_check
    global fed_check, loss_train_collect, acc_train_collect, count1, idx_collect
    global w_locals_server, w_glob_server, loss_train_collect_user, acc_train_collect_user
    global precision_train_collect_user, recall_train_collect_user, auc_train_collect_user
    global precision_train_collect, recall_train_collect, auc_train_collect

    net_server = net_model_server[idx].to(device)
    net_server.train()
    optimizer.zero_grad()
    fx_client, y = fx_client.to(device), y.to(device)
    fx_server = net_server(fx_client)
    loss = criterion(fx_server, y)
    acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes=3)
    loss.backward()
    dfx_client = fx_client.grad.clone().detach()
    optimizer.step()
    batch_loss_train.append(loss.item()); batch_acc_train.append(acc.item()); batch_precision_train.append(precision.item()); batch_recall_train.append(recall.item()); batch_auc_train.append(auc.item())
    net_model_server[idx] = net_server
    count1 += 1
    if count1 == len_batch:
        acc_avg_train=sum(batch_acc_train)/len(batch_acc_train); loss_avg_train=sum(batch_loss_train)/len(batch_loss_train); precision_avg_train=sum(batch_precision_train)/len(batch_precision_train); recall_avg_train=sum(batch_recall_train)/len(batch_recall_train); auc_avg_train=sum(batch_auc_train)/len(batch_auc_train)
        batch_acc_train.clear();batch_loss_train.clear();batch_precision_train.clear();batch_recall_train.clear();batch_auc_train.clear();
        count1=0
        print(f'Client{idx} Train => Local Epoch: {l_epoch_count} \tAcc: {acc_avg_train:.3f} \tLoss: {loss_avg_train:.4f}')
        if l_epoch_count==l_epoch-1:
            l_epoch_check=True
            w_locals_server.append(copy.deepcopy(net_server.state_dict()))
            loss_train_collect_user.append(loss_avg_train);acc_train_collect_user.append(acc_avg_train);precision_train_collect_user.append(precision_avg_train);recall_train_collect_user.append(recall_avg_train);auc_train_collect_user.append(auc_avg_train)
            if idx not in idx_collect: idx_collect.append(idx)
        if len(idx_collect)==num_users:
            fed_check=True
            w_glob_server=FedProx(w_locals_server)
            net_glob_server.load_state_dict(w_glob_server)
            for i in range(num_users): net_model_server[i].load_state_dict(w_glob_server)
            w_locals_server.clear();idx_collect.clear()
            acc_avg_all_user_train=sum(acc_train_collect_user)/len(acc_train_collect_user);loss_avg_all_user_train=sum(loss_train_collect_user)/len(loss_train_collect_user);precision_avg_all_user_train=sum(precision_train_collect_user)/len(precision_train_collect_user);recall_avg_all_user_train=sum(recall_train_collect_user)/len(recall_train_collect_user);auc_avg_all_user_train=sum(auc_train_collect_user)/len(auc_train_collect_user)
            loss_train_collect.append(loss_avg_all_user_train);acc_train_collect.append(acc_avg_all_user_train);precision_train_collect.append(precision_avg_all_user_train);recall_train_collect.append(recall_avg_all_user_train);auc_train_collect.append(auc_avg_all_user_train)
            acc_train_collect_user.clear();loss_train_collect_user.clear();precision_train_collect_user.clear();recall_train_collect_user.clear();auc_train_collect_user.clear()
            print(f'Train: Round {l_epoch_count:3d}, Avg Acc {acc_avg_all_user_train:.3f} | Avg Loss {loss_avg_all_user_train:.3f}')
    return dfx_client

def evaluate_server(fx_client, y, idx, len_batch, ell):
    """Lógica de avaliação que roda no servidor."""
    global net_model_server, criterion, batch_acc_test, batch_loss_test, fed_check
    global loss_test_collect, acc_test_collect, count2, l_epoch_check
    global loss_test_collect_user, acc_test_collect_user, precision_test_collect_user, recall_test_collect_user, auc_test_collect_user, f1_test_collect_user
    global precision_test_collect, recall_test_collect, auc_test_collect, f1_test_collect

    net = copy.deepcopy(net_model_server[idx]).to(device)
    net.eval()
    with torch.no_grad():
        fx_client, y = fx_client.to(device), y.to(device)
        fx_server = net(fx_client)
        loss = criterion(fx_server, y)
        acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes=3)
        batch_loss_test.append(loss.item()); batch_acc_test.append(acc.item()); batch_prec_test.append(precision.item()); batch_recall_test.append(recall.item()); batch_auc_test.append(auc.item()); batch_f1_test.append(f1.item())
        count2 += 1
        if count2 == len_batch:
            acc_avg_test=sum(batch_acc_test)/len(batch_acc_test);loss_avg_test=sum(batch_loss_test)/len(batch_loss_test);precision_avg_test=sum(batch_prec_test)/len(batch_prec_test);recall_avg_test=sum(batch_recall_test)/len(batch_recall_test);auc_avg_test=sum(batch_auc_test)/len(batch_auc_test);f1_avg_test=sum(batch_f1_test)/len(batch_f1_test)
            batch_acc_test.clear();batch_loss_test.clear();batch_prec_test.clear();batch_recall_test.clear();batch_auc_test.clear();batch_f1_test.clear()
            count2=0
            print('Client{} Test => \tAcc: {:.3f} \tLoss: {:.4f} \tF1: {:.3f}'.format(idx, acc_avg_test, loss_avg_test, f1_avg_test))
            if l_epoch_check:
                l_epoch_check=False
                loss_test_collect_user.append(loss_avg_test);acc_test_collect_user.append(acc_avg_test);precision_test_collect_user.append(precision_avg_test);recall_test_collect_user.append(recall_avg_test);auc_test_collect_user.append(auc_avg_test);f1_test_collect_user.append(f1_avg_test)
            if fed_check:
                fed_check=False
                acc_avg_all_user=sum(acc_test_collect_user)/len(acc_test_collect_user);loss_avg_all_user=sum(loss_test_collect_user)/len(loss_test_collect_user);precision_avg_all_user=sum(precision_test_collect_user)/len(precision_test_collect_user);recall_avg_all_user=sum(recall_test_collect_user)/len(recall_test_collect_user);auc_avg_all_user=sum(auc_test_collect_user)/len(auc_test_collect_user);f1_avg_all_user=sum(f1_test_collect_user)/len(f1_test_collect_user)
                loss_test_collect.append(loss_avg_all_user);acc_test_collect.append(acc_avg_all_user);precision_test_collect.append(precision_avg_all_user);recall_test_collect.append(recall_avg_all_user);auc_test_collect.append(auc_avg_all_user);f1_test_collect.append(f1_avg_all_user)
                acc_test_collect_user.clear();loss_test_collect_user.clear();precision_test_collect_user.clear();recall_test_collect_user.clear();auc_test_collect_user.clear();f1_test_collect_user.clear()
                print("="*60); print(f'Test: Round {ell:3d}, Avg Acc {acc_avg_all_user:.3f} | Avg Loss {loss_avg_all_user:.3f} | F1 {f1_avg_all_user:.3f}'); print("="*60)
    return

def evaluate_accuracy(net, loader, device, return_conf_matrix=False, num_classes=3):
    """Avalia o modelo combinado final no conjunto de teste completo."""
    net.eval()
    all_preds, all_labels, all_outputs = [], [], []
    with torch.no_grad():
        for images, labels in loader:
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs, 1)
            all_outputs.append(outputs.cpu())
            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    all_outputs=torch.cat(all_outputs,dim=0);all_preds=torch.tensor(all_preds);all_labels=torch.tensor(all_labels)
    accuracy=torchmetrics.functional.accuracy(all_preds,all_labels,task='multiclass',num_classes=num_classes).item()
    precision=torchmetrics.functional.precision(all_preds,all_labels,average='macro',task='multiclass',num_classes=num_classes).item()
    recall=torchmetrics.functional.recall(all_preds,all_labels,average='macro',task='multiclass',num_classes=num_classes).item()
    f1=torchmetrics.functional.f1_score(all_preds,all_labels,average='macro',task='multiclass',num_classes=num_classes).item()
    auc=torchmetrics.functional.auroc(F.softmax(all_outputs,dim=1),all_labels,task="multiclass",num_classes=num_classes).item()
    conf_matrix=confusion_matrix(all_labels.cpu().numpy(),all_preds.cpu().numpy())
    if return_conf_matrix: return accuracy,precision,recall,f1,auc,conf_matrix
    return accuracy,precision,recall,f1,auc

def dataset_iid(indices, num_users):
    """Divide o dataset de forma IID entre os usuários."""
    num_items_per_user = len(indices) // num_users
    dict_users, all_idxs = {}, list(indices)
    for i in range(num_users):
        dict_users[i] = set(np.random.choice(all_idxs, num_items_per_user, replace=False))
        all_idxs = list(set(all_idxs) - dict_users[i])
    return dict_users

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.RandomRotation(10),
    transforms.RandomAffine(degrees=7, translate=(0.05,0.05), scale=(0.9,1.1)),
    transforms.ToTensor(), # <-- Convertido para Tensor PRIMEIRO
    RandomNoise(p=0.2, mean=0., std=0.05), # <-- Ruído aplicado no Tensor DEPOIS
    transforms.Normalize([0.5]*3, [0.5]*3),
])
test_transform = transforms.Compose([transforms.Resize((224,224)), transforms.Grayscale(num_output_channels=3), transforms.ToTensor(), transforms.Normalize([0.5]*3,[0.5]*3)])

full_dataset = datasets.ImageFolder(root=data_path)
labels_all = [lbl for _, lbl in full_dataset.samples]
train_idx, test_idx = train_test_split(np.arange(len(full_dataset)), test_size=0.2, stratify=labels_all, random_state=SEED)

main_train_dataset = CustomDataset(Subset(full_dataset, train_idx), transform=train_transform)
main_test_dataset = CustomDataset(Subset(full_dataset, test_idx), transform=test_transform)

client_counts = [3, 5, 7]
num_classes = 3

for num_users in client_counts:
    print(f"\n{'='*80}")
    print(f"INICIANDO TREINAMENTO PARA {num_users} CLIENTES")
    print(f"{'='*80}\n")

    # --- PARÂMETROS E REINICIALIZAÇÃO DE ESTADO ---
    epochs = 80
    frac = 1
    lr = 0.0001
    batch_size = 32
    weight_decay = 5e-4
    mu = 0.01

    net_glob_client = DenseNet169_client_side().to(device)
    net_glob_server = DenseNet169_server_side(num_classes=num_classes).to(device)
    net_model_server = [copy.deepcopy(net_glob_server) for _ in range(num_users)]
    optimizers_server = [torch.optim.Adam(net_model_server[i].parameters(), lr=lr, weight_decay=weight_decay) for i in range(num_users)]

    loss_train_collect, acc_train_collect, loss_test_collect, acc_test_collect = [],[],[],[]
    precision_train_collect,recall_train_collect,auc_train_collect = [],[],[]
    precision_test_collect,recall_test_collect,auc_test_collect,f1_test_collect = [],[],[],[]
    batch_acc_train,batch_loss_train,batch_precision_train,batch_recall_train,batch_auc_train = [],[],[],[],[]
    batch_acc_test,batch_loss_test,batch_prec_test,batch_recall_test,batch_auc_test,batch_f1_test = [],[],[],[],[],[]
    acc_train_collect_user,loss_train_collect_user,precision_train_collect_user,recall_train_collect_user,auc_train_collect_user = [],[],[],[],[]
    acc_test_collect_user,loss_test_collect_user,precision_test_collect_user,recall_test_collect_user,auc_test_collect_user,f1_test_collect_user = [],[],[],[],[],[]
    w_locals_server, idx_collect = [], []
    count1, count2 = 0, 0
    l_epoch_check, fed_check = False, False

    dict_users = dataset_iid(train_idx, num_users)
    dict_users_test = dataset_iid(test_idx, num_users)

    labels = [label for _, label in main_train_dataset]
    class_weights = compute_class_weight('balanced', classes=np.unique(np.array(labels)), y=labels)
    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)
    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)
    test_loader = DataLoader(main_test_dataset, batch_size=batch_size, shuffle=False)

    checkpoint_path = f'best_model_{num_users}_clients.pt'
    early_stopping = EarlyStopping(patience=10, verbose=True, save_path=checkpoint_path)

for iter_epoch in range(epochs):
        start_time = time.time()
        m = max(int(frac * num_users), 1)
        idxs_users = np.random.choice(range(num_users), m, replace=False)
        w_locals_client = []

        for idx in idxs_users:
            local = Client(net_glob_client, idx, lr, device, mu=mu, idxs=dict_users[idx], idxs_test=dict_users_test[idx])
            w_client = local.train(net=copy.deepcopy(net_glob_client))
            w_locals_client.append(copy.deepcopy(w_client))
            local.evaluate(net=copy.deepcopy(net_glob_client), ell=iter_epoch)

        w_glob_client = FedProx(w_locals_client)
        net_glob_client.load_state_dict(w_glob_client)

        print(f"Epoch {iter_epoch + 1}/{epochs} - Time taken: {time.time() - start_time:.2f}s")
        if len(loss_test_collect) > 0:
            val_loss = loss_test_collect[-1]
            early_stopping(val_loss, (net_glob_client, net_glob_server))
            if early_stopping.early_stop:
                print("Early stopping triggered.")
                break

print(f"\nTreinamento para {num_users} clientes concluído!")

print("\nGerando gráficos e avaliação final...")
if acc_train_collect:
    epochs_range = range(1, len(acc_train_collect) + 1)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))
    fig.suptitle(f'Métricas Primárias ({num_users} Clientes)', fontsize=20)
    ax1.plot(epochs_range, acc_train_collect, 'o-', label='Acurácia de Treino')
    ax1.plot(epochs_range, acc_test_collect, 's-', label='Acurácia de Validação')
    ax1.set_title('Acurácia vs. Época'); ax1.set_xlabel('Época'); ax1.set_ylabel('Acurácia'); ax1.legend()
    ax2.plot(epochs_range, loss_train_collect, 'o-', label='Perda de Treino')
    ax2.plot(epochs_range, loss_test_collect, 's-', label='Perda de Validação')
    ax2.set_title('Perda vs. Época'); ax2.set_xlabel('Época'); ax2.set_ylabel('Perda'); ax2.legend()
    plt.show()

try:
    checkpoint = torch.load(checkpoint_path)
    net_glob_client.load_state_dict(checkpoint['net_glob_client_state_dict'])
    net_glob_server.load_state_dict(checkpoint['net_glob_server_state_dict'])

    final_model = CombinedModel(net_glob_client, net_glob_server).to(device)
    accuracy, precision, recall, f1, auc, conf_matrix = evaluate_accuracy(final_model, test_loader, device, return_conf_matrix=True, num_classes=num_classes)

    print(f"\n--- Métricas Finais ({num_users} Clientes) ---")
    print(f"  Acurácia: {accuracy:.4f}, Precisão: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")

    plt.figure(figsize=(10, 8))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))
    plt.title(f'Matriz de Confusão ({num_users} Clientes)', fontsize=18)
    plt.xlabel('Rótulo Previsto'); plt.ylabel('Rótulo Verdadeiro')
    plt.show()

except FileNotFoundError:
    print(f"Arquivo de checkpoint '{checkpoint_path}' não encontrado.")
except Exception as e:
    print(f"Ocorreu um erro na avaliação final: {e}")

if not recall_train_collect or not auc_train_collect:
    print("Dados de métricas de Recall/AUC não foram coletados. Não é possível gerar os gráficos.")
else:
    # Cria o eixo X com base no número de épocas executadas
    epochs_range = range(1, len(recall_train_collect) + 1)
    plt.style.use('seaborn-v0_8-whitegrid')

    # --- Cria a figura para os gráficos de Recall e AUC ---
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))
    fig.suptitle('Desempenho de Recall e AUC por Época', fontsize=20)

    # --- Gráfico de Recall ---
    ax1.plot(epochs_range, recall_train_collect, 'o-', label='Recall de Treino', color='purple')
    ax1.plot(epochs_range, recall_test_collect, 's-', label='Recall de Validação', color='orange')
    ax1.set_title('Recall (Macro) vs. Época', fontsize=16)
    ax1.set_xlabel('Época', fontsize=12)
    ax1.set_ylabel('Recall', fontsize=12)
    ax1.legend(fontsize=12)
    ax1.grid(True)
    ax1.tick_params(axis='both', which='major', labelsize=10)

    # --- Gráfico de AUC ---
    ax2.plot(epochs_range, auc_train_collect, 'o-', label='AUC de Treino', color='green')
    ax2.plot(epochs_range, auc_test_collect, 's-', label='AUC de Validação', color='red')
    ax2.set_title('AUC (Area Under Curve) vs. Época', fontsize=16)
    ax2.set_xlabel('Época', fontsize=12)
    ax2.set_ylabel('AUC', fontsize=12)
    ax2.legend(fontsize=12)
    ax2.grid(True)
    ax2.tick_params(axis='both', which='major', labelsize=10)

    # Ajusta o layout para evitar sobreposição de títulos e mostra o gráfico
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plt.show()