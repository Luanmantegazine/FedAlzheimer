{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz2Ntnx6Q435",
        "outputId": "c96257ef-2fc2-495c-9454-ba97e42c64b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.0+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGN9Ju7v7w-",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:45:56.686070Z",
          "start_time": "2024-10-07T19:45:31.675762Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbf4814-bc0a-4dac-cd25-bc0adc60bf3a"
      },
      "source": [
        "import torch\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from torch import nn\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from collections import Counter\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from glob import glob\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Subset\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlknLHbixiCq"
      },
      "source": [
        "#Definindo o n√∫mero de clientes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtpTQpfMxhka",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:46:05.441136Z",
          "start_time": "2024-10-07T19:46:05.403083Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3aa48aa-92ed-4714-fbdc-77187b176061"
      },
      "source": [
        "num_users = 3\n",
        "num_classes =  3\n",
        "epochs = 80\n",
        "frac = 1\n",
        "lr= 0.0001\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIgHK_5Cx0Xo"
      },
      "source": [
        "#Importando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TDdVPq2x4cf",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:46:10.046762Z",
          "start_time": "2024-10-07T19:46:09.987699Z"
        }
      },
      "source": [
        "data_path='/content/drive/MyDrive/ADNI'\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=data_path)\n",
        "\n",
        "all_indices= list(range(len(full_dataset)))\n",
        "np.random.shuffle(all_indices)\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "train_indices = all_indices[:train_size]\n",
        "test_indices = all_indices[train_size:]\n",
        "\n",
        "\n",
        "train_dataset = Subset(full_dataset, train_indices)\n",
        "test_dataset = Subset(full_dataset, test_indices)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, subset, transform=None):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.subset[index]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "\n",
        "train_dataset = CustomDataset(train_dataset, transform=train_transform)\n",
        "test_dataset = CustomDataset(test_dataset, transform=test_transform)\n",
        "\n",
        "labels = [label for _, label in train_dataset]\n",
        "class_counts = np.unique(labels)\n",
        "class_weights = compute_class_weight('balanced', classes=class_counts, y=labels)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-07T19:48:11.340023Z",
          "start_time": "2024-10-07T19:46:13.152895Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFYRknxiP9UL",
        "outputId": "07034cb3-9e9f-44ee-b7f2-a51d7977ff65"
      },
      "cell_type": "code",
      "source": [
        "def count_samples_per_class(dataset):\n",
        "    labels = [label for _, label in dataset]\n",
        "    class_counts = Counter(labels)\n",
        "    return class_counts\n",
        "\n",
        "train_class_counts = count_samples_per_class(train_dataset)\n",
        "print(\"Initial class distribution in training set:\", train_class_counts)\n",
        "\n",
        "\n",
        "max_count = max(train_class_counts.values())\n",
        "\n",
        "\n",
        "class_to_indices = {class_idx: [] for class_idx in range(num_classes)}\n",
        "for idx, (_, label) in enumerate(train_dataset):\n",
        "    class_to_indices[label].append(idx)\n",
        "\n",
        "oversampled_indices = []\n",
        "for class_idx, indices in class_to_indices.items():\n",
        "\n",
        "    num_to_add = max_count - len(indices)\n",
        "    if num_to_add > 0:\n",
        "        indices_to_add = np.random.choice(indices, size=num_to_add, replace=True)\n",
        "        oversampled_indices.extend(indices)\n",
        "        oversampled_indices.extend(indices_to_add)\n",
        "    else:\n",
        "        oversampled_indices.extend(indices)\n",
        "\n",
        "print(f\"Total samples after oversampling: {len(oversampled_indices)}\")\n",
        "\n",
        "oversampled_train_dataset = Subset(train_dataset, oversampled_indices)\n",
        "\n",
        "train_loader = DataLoader(oversampled_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial class distribution in training set: Counter({2: 212, 1: 147, 0: 77})\n",
            "Total samples after oversampling: 636\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:21.433843Z",
          "start_time": "2024-10-07T19:49:21.346301Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O_zQQY1P9UM",
        "outputId": "01501223-1811-4823-aa7f-6017aa35fb78"
      },
      "cell_type": "code",
      "source": [
        "def get_class_distribution(loader):\n",
        "    class_counts = Counter()\n",
        "    for _, labels in loader:\n",
        "        class_counts.update(labels.numpy())\n",
        "    return class_counts\n",
        "\n",
        "new_train_class_counts = get_class_distribution(train_loader)\n",
        "print(\"New class distribution in training loader:\", new_train_class_counts)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New class distribution in training loader: Counter({0: 212, 1: 212, 2: 212})\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzTpOB0SyjLK"
      },
      "source": [
        "#Definindo o treinamento dos clientes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Xcv6TMcynpJ",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:26.603179Z",
          "start_time": "2024-10-07T19:49:26.291781Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562a1cdf-1664-498d-f6c3-f7e8c34a81f5"
      },
      "source": [
        "class DenseNet_client_side(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenseNet_client_side, self).__init__()\n",
        "        densenet = models.densenet121(pretrained=False)\n",
        "        # Extract features up to transition2\n",
        "        self.features = nn.Sequential(*list(densenet.features.children())[:8])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x\n",
        "\n",
        "net_glob_client = DenseNet_client_side()\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n",
        "    net_glob_client = nn.DataParallel(net_glob_client)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPhaspYryuye"
      },
      "source": [
        "#Definindo o treinamento do servidor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LapoJhY6yq28",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:29.755614Z",
          "start_time": "2024-10-07T19:49:29.614885Z"
        }
      },
      "source": [
        "class DenseNet_server_side(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(DenseNet_server_side, self).__init__()\n",
        "        densenet = models.densenet121(pretrained=False)\n",
        "        self.features = nn.Sequential(*list(densenet.features.children())[8:])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),  # Adicionando dropout\n",
        "            nn.Linear(512, num_classes)\n",
        "        )  # DenseNet121 has 1024 features at the end\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = F.relu(x, inplace=True)\n",
        "        x = F.adaptive_avg_pool2d(x, (1,1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "net_glob_server = DenseNet_server_side(num_classes=3)\n",
        "if torch.cuda.device_count() > 1:\n",
        "    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n",
        "    net_glob_server = nn.DataParallel(net_glob_server)\n",
        "    net_glob_server = net_glob_server.to(device)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiPpKWagy5OH",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:30.537102Z",
          "start_time": "2024-10-07T19:49:30.526695Z"
        }
      },
      "source": [
        "loss_train_collect = []\n",
        "acc_train_collect = []\n",
        "loss_test_collect = []\n",
        "acc_test_collect = []\n",
        "auc_train_collect = []\n",
        "auc_test_collect = []\n",
        "batch_acc_train = []\n",
        "batch_loss_train = []\n",
        "batch_precision_train = []\n",
        "batch_recall_train = []\n",
        "acc_avg_all_user_train = []\n",
        "loss_avg_all_user_train = []\n",
        "loss_avg_train_all = []\n",
        "acc_avg_train_all = []\n",
        "acc_train_collect_user = []\n",
        "loss_train_collect_user = []\n",
        "loss_test_collect_user = []\n",
        "batch_auc_train = []\n",
        "batch_acc_test = []\n",
        "batch_loss_test = []\n",
        "batch_prec_test = []\n",
        "batch_recall_test = []\n",
        "\n",
        "count1 = 0\n",
        "count2 = 0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r48wsNx9y7VM",
        "ExecuteTime": {
          "end_time": "2024-10-07T20:03:55.074329Z",
          "start_time": "2024-10-07T20:03:53.189535Z"
        }
      },
      "source": [
        "def FedSGD(gradients_list):\n",
        "    avg_grad = {}\n",
        "    for name in gradients_list[0].keys():\n",
        "        grad_sum = torch.zeros_like(gradients_list[0][name], device=device)\n",
        "        for gradients in gradients_list:\n",
        "            grad_sum += gradients[name].to(device)\n",
        "        avg_grad[name] = grad_sum / len(gradients_list)\n",
        "    return avg_grad\n",
        "\n",
        "def calculate_metrics(fx, y, num_classes):\n",
        "    preds = fx.argmax(dim=1)\n",
        "    accuracy = torchmetrics.functional.accuracy(preds, y, task='multiclass', num_classes=num_classes)\n",
        "    precision = torchmetrics.functional.precision(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
        "    recall = torchmetrics.functional.recall(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
        "    f1 = torchmetrics.functional.f1_score(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
        "    auc = torchmetrics.functional.auroc(F.softmax(fx, dim=1), y, task='multiclass', num_classes=num_classes)\n",
        "    return accuracy, precision, recall, f1, auc\n",
        "\n",
        "w_glob_server = net_glob_server.state_dict()\n",
        "w_locals_server = []\n",
        "weight_decay = 1e-4\n",
        "\n",
        "idx_collect = []\n",
        "l_epoch_check = False\n",
        "fed_check = False\n",
        "\n",
        "net_model_server = [copy.deepcopy(net_glob_server).to(device) for _ in range(num_users)]\n",
        "\n",
        "net_server = copy.deepcopy(net_model_server[0]).to(device)\n",
        "optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler_server = torch.optim.lr_scheduler.StepLR(optimizer_server, step_size=30, gamma=0.1)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, validation_loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = validation_loss\n",
        "        elif validation_loss > self.best_loss - self.min_delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = validation_loss\n",
        "            self.counter = 0\n",
        "\n",
        "# Instanciar o early stopping\n",
        "early_stopping = EarlyStopping(patience=7, min_delta=0.01)"
      ],
      "metadata": {
        "id": "OpN84N92ASL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybaVUIqZy-1j",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:31.884576Z",
          "start_time": "2024-10-07T19:49:31.877793Z"
        }
      },
      "source": [
        "def train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch, num_classes=3):\n",
        "    global net_model_server, criterion, optimizer_server, device\n",
        "    global batch_acc_train, batch_loss_train, batch_precision_train, batch_recall_train, batch_auc_train\n",
        "    global l_epoch_check, fed_check, loss_train_collect, acc_train_collect, count1\n",
        "    global acc_avg_all_user_train, loss_avg_all_user_train, idx_collect, w_locals_server, w_glob_server, net_server\n",
        "    global loss_train_collect_user, acc_train_collect_user, lr\n",
        "\n",
        "    # Certifique-se de que o modelo est√° no dispositivo correto\n",
        "    net_server = net_model_server[idx].to(device)\n",
        "    net_server.train()\n",
        "    optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr)\n",
        "\n",
        "    optimizer_server.zero_grad()\n",
        "    fx_client = fx_client.to(device)\n",
        "    y = y.to(device)  # Move os r√≥tulos para o mesmo dispositivo\n",
        "\n",
        "    # Forward pass\n",
        "    fx_server = net_server(fx_client)\n",
        "\n",
        "    # Calcule a perda\n",
        "    loss = criterion(fx_server, y)\n",
        "    acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes)\n",
        "    loss.backward()\n",
        "\n",
        "    # Coletar gradientes como um dicion√°rio\n",
        "    gradients = {name: param.grad.clone().detach() for name, param in net_server.named_parameters() if param.grad is not None}\n",
        "\n",
        "    dfx_client = fx_client.grad.clone().detach()\n",
        "\n",
        "    # Atualize as m√©tricas de treinamento do lote\n",
        "    batch_loss_train.append(loss.item())\n",
        "    batch_acc_train.append(acc.item())\n",
        "    batch_precision_train.append(precision.item())\n",
        "    batch_recall_train.append(recall.item())\n",
        "    batch_auc_train.append(auc.item())\n",
        "\n",
        "    net_model_server[idx].server_gradients = gradients\n",
        "\n",
        "    count1 += 1\n",
        "    if count1 == len_batch:\n",
        "        acc_avg_train = sum(batch_acc_train) / len(batch_acc_train)\n",
        "        loss_avg_train = sum(batch_loss_train) / len(batch_loss_train)\n",
        "        precision_avg_train = sum(batch_precision_train) / len(batch_precision_train)\n",
        "        recall_avg_train = sum(batch_recall_train) / len(batch_recall_train)\n",
        "        auc_avg_train = sum(batch_auc_train) / len(batch_auc_train)\n",
        "\n",
        "        batch_acc_train.clear()\n",
        "        batch_loss_train.clear()\n",
        "        batch_precision_train.clear()\n",
        "        batch_recall_train.clear()\n",
        "        batch_auc_train.clear()\n",
        "        count1 = 0\n",
        "\n",
        "\n",
        "        print(f'Client{idx} Train => Local Epoch: {l_epoch_count} \\tAcc: {acc_avg_train:.3f} \\tLoss: {loss_avg_train:.4f} \\tPrecision: {precision_avg_train:.3f} \\tRecall: {recall_avg_train:.3f} \\tAUC: {auc_avg_train:.3f}')\n",
        "\n",
        "        if l_epoch_count == l_epoch - 1:\n",
        "            l_epoch_check = True\n",
        "            w_locals_server.append(gradients)\n",
        "\n",
        "            acc_avg_all_user_train = acc_avg_train\n",
        "            loss_avg_all_user_train = loss_avg_train\n",
        "\n",
        "            loss_train_collect_user.append(loss_avg_train_all)\n",
        "            acc_train_collect_user.append(acc_avg_train_all)\n",
        "\n",
        "            if idx not in idx_collect:\n",
        "                idx_collect.append(idx)\n",
        "\n",
        "            if len(idx_collect) == num_users:\n",
        "                fed_check = True\n",
        "\n",
        "\n",
        "    return dfx_client\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-azC4sjfzBte",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:32.566017Z",
          "start_time": "2024-10-07T19:49:32.552583Z"
        }
      },
      "source": [
        "def evaluate_server(fx_client, y, idx, len_batch, ell, num_classes=3):\n",
        "    global net_model_server, criterion, batch_acc_test, batch_loss_test, check_fed, net_server, net_glob_server\n",
        "    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, w_glob_server, l_epoch_check, fed_check\n",
        "    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n",
        "\n",
        "    batch_precision_test = []\n",
        "    acc_test_collect_user = []\n",
        "    batch_recall_test = []\n",
        "    batch_auc_test = []\n",
        "    batch_f1_test = []\n",
        "\n",
        "    net = copy.deepcopy(net_model_server[idx]).to(device)\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fx_client = fx_client.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        fx_server = net(fx_client)\n",
        "        loss = criterion(fx_server, y)\n",
        "\n",
        "        acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes)\n",
        "\n",
        "        batch_loss_test.append(loss.item())\n",
        "        batch_acc_test.append(acc.item())\n",
        "        batch_precision_test.append(precision.item())\n",
        "        batch_recall_test.append(recall.item())\n",
        "        batch_auc_test.append(auc.item())\n",
        "        batch_f1_test.append(f1.item())\n",
        "\n",
        "        count2 += 1\n",
        "        if count2 == len_batch:\n",
        "            acc_avg_test = sum(batch_acc_test) / len(batch_acc_test)\n",
        "            loss_avg_test = sum(batch_loss_test) / len(batch_loss_test)\n",
        "            precision_avg_test = sum(batch_precision_test) / len(batch_precision_test)\n",
        "            recall_avg_test = sum(batch_recall_test) / len(batch_recall_test)\n",
        "            auc_avg_test = sum(batch_auc_test) / len(batch_auc_test)\n",
        "            f1_avg_test = sum(batch_f1_test) / len(batch_f1_test)\n",
        "\n",
        "            batch_acc_test = []\n",
        "            batch_loss_test = []\n",
        "            batch_precision_test = []\n",
        "            batch_recall_test = []\n",
        "            batch_auc_test = []\n",
        "            batch_f1_test = []\n",
        "            count2 = 0\n",
        "\n",
        "            print('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f} \\tPrecision: {:.3f} \\tRecall: {:.3f} \\tAUC: {:.3f} \\tF1-Score: {:.3f}'.format(\n",
        "                idx, acc_avg_test, loss_avg_test, precision_avg_test, recall_avg_test, auc_avg_test, f1_avg_test))\n",
        "\n",
        "            if l_epoch_check:\n",
        "                l_epoch_check = False\n",
        "\n",
        "                acc_avg_test_all = acc_avg_test\n",
        "                loss_avg_test_all = loss_avg_test\n",
        "\n",
        "                loss_test_collect_user.append(loss_avg_test_all)\n",
        "                acc_test_collect_user.append(acc_avg_test_all)\n",
        "\n",
        "            if fed_check:\n",
        "                fed_check = False\n",
        "                print(\"------------------------------------------------\")\n",
        "                print(\"------ Federation process at Server-Side ------- \")\n",
        "                print(\"------------------------------------------------\")\n",
        "\n",
        "\n",
        "                acc_avg_all_user = sum(acc_test_collect_user) / len(acc_test_collect_user)\n",
        "                loss_avg_all_user = sum(loss_test_collect_user) / len(loss_test_collect_user)\n",
        "\n",
        "                loss_test_collect.append(loss_avg_all_user)\n",
        "                acc_test_collect.append(acc_avg_all_user)\n",
        "                acc_test_collect_user = []\n",
        "                loss_test_collect_user = []\n",
        "\n",
        "                print(\"====================== SERVER V1==========================\")\n",
        "                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train, loss_avg_all_user_train))\n",
        "                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user, loss_avg_all_user))\n",
        "                print(\"==========================================================\")\n",
        "            return"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82R9R7c6zK3x",
        "ExecuteTime": {
          "end_time": "2024-10-07T19:49:33.295508Z",
          "start_time": "2024-10-07T19:49:33.259740Z"
        }
      },
      "source": [
        "def evaluate_accuracy(net, loader, device, return_conf_matrix=False, num_classes=3):\n",
        "    net.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "    all_preds = torch.tensor(all_preds)\n",
        "    all_labels = torch.tensor(all_labels)\n",
        "\n",
        "\n",
        "    accuracy = torchmetrics.functional.accuracy(all_preds, all_labels, task='multiclass', num_classes=num_classes).item()\n",
        "    precision = torchmetrics.functional.precision(all_preds, all_labels, average='macro', task='multiclass', num_classes=num_classes).item()\n",
        "    recall = torchmetrics.functional.recall(all_preds, all_labels, average='macro', task='multiclass', num_classes=num_classes).item()\n",
        "    f1 = torchmetrics.functional.f1_score(all_preds, all_labels, average='macro', task='multiclass', num_classes=num_classes).item()\n",
        "    auc = torchmetrics.functional.auroc(F.softmax(outputs, dim=1), all_labels, task='multiclass', num_classes=num_classes).item()\n",
        "\n",
        "\n",
        "    conf_matrix = confusion_matrix(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n",
        "\n",
        "    if return_conf_matrix:\n",
        "        return accuracy, precision, recall, f1, auc, conf_matrix\n",
        "    else:\n",
        "        return accuracy, precision, recall, f1, auc\n",
        "\n",
        "class DatasetSplit(Dataset):\n",
        "    def __init__(self, dataset, indices, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = list(indices)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.indices[idx]\n",
        "        image, label = self.dataset[real_idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "class Client(object):\n",
        "    def __init__(self, net_client_model, idx, lr, device, train_loader=None, test_loader=None, idxs=None, idxs_test=None):\n",
        "        self.idx = idx\n",
        "        self.device = device\n",
        "        self.lr = lr\n",
        "        self.local_ep = 1\n",
        "        self.train_dataset = DatasetSplit(full_dataset, train_indices, transform=train_transform)\n",
        "        self.test_dataset = DatasetSplit(full_dataset, test_indices, transform=test_transform)\n",
        "        self.ldr_train = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self.ldr_test = DataLoader(self.test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    def train(self, net):\n",
        "        net.train()\n",
        "        optimizer_client = torch.optim.Adam(net.parameters(), lr=self.lr)\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer_client, step_size=30, gamma=0.1)\n",
        "\n",
        "        for local_epoch in range(self.local_ep):\n",
        "            len_batch = len(self.ldr_train)\n",
        "\n",
        "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
        "                images, labels = images.to(self.device), labels.to(self.device)\n",
        "                optimizer_client.zero_grad()\n",
        "                fx = net(images)\n",
        "                client_fx = fx.clone().detach().requires_grad_(True)\n",
        "                dfx = train_server(client_fx, labels, local_epoch, self.local_ep, self.idx, len_batch)\n",
        "                fx.backward(dfx)\n",
        "                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
        "                optimizer_client.step()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "        gradients = {name: param.grad.clone() for name, param in net.named_parameters()}\n",
        "        return gradients\n",
        "\n",
        "    def get_server_gradients_from_train_server(self):\n",
        "        return net_model_server[self.idx].server_gradients\n",
        "\n",
        "\n",
        "    def evaluate(self, net, ell, num_classes=3):\n",
        "      net.eval()\n",
        "      with torch.no_grad():\n",
        "        len_batch = len(self.ldr_test)\n",
        "        for batch_idx, (images, labels) in enumerate(self.ldr_test):\n",
        "            images, labels = images.to(self.device), labels.to(self.device)\n",
        "            fx = net(images)\n",
        "            evaluate_server(fx, labels, self.idx, len_batch, ell, num_classes)\n",
        "        return\n",
        "\n",
        "def dataset_iid(indices, num_users):\n",
        "    indices = np.array(indices)\n",
        "    num_items_per_user = len(indices) // num_users\n",
        "    dict_users = {}\n",
        "    for i in range(num_users):\n",
        "        start_idx = i * num_items_per_user\n",
        "        end_idx = (i + 1) * num_items_per_user if i != num_users - 1 else len(indices)\n",
        "        dict_users[i] = indices[start_idx:end_idx]\n",
        "    return dict_users\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Treino!\n"
      ],
      "metadata": {
        "id": "I50k6NHR8V9x"
      }
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-07T20:11:06.479394Z",
          "start_time": "2024-10-07T20:04:08.985995Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EVBBDOHuP9UO",
        "outputId": "6312dae2-3078-4971-d91a-3f204103b183"
      },
      "cell_type": "code",
      "source": [
        "epoch_times = []\n",
        "\n",
        "dict_users = dataset_iid(train_indices, num_users)\n",
        "dict_users_test = dataset_iid(test_indices, num_users)\n",
        "net_glob_client.train()\n",
        "\n",
        "w_glob_client = net_glob_client.state_dict()\n",
        "\n",
        "\n",
        "for iter in range(epochs):\n",
        "    start_time = time.time()\n",
        "    grad_locals_client = []\n",
        "    w_locals_server = []\n",
        "    m = max(int(frac * num_users), 1)\n",
        "    idxs_users = np.random.choice(range(num_users), m, replace=False)\n",
        "    w_locals_client = []\n",
        "\n",
        "    for idx in idxs_users:\n",
        "        local = Client(\n",
        "            net_glob_client,\n",
        "            idx,\n",
        "            lr,\n",
        "            device,\n",
        "            idxs=dict_users[idx],\n",
        "            idxs_test=dict_users_test[idx]\n",
        "        )\n",
        "\n",
        "        # Client training\n",
        "        gradients_client = local.train(net=copy.deepcopy(net_glob_client).to(device))\n",
        "        if gradients_client:\n",
        "            grad_locals_client.append(gradients_client)\n",
        "\n",
        "        # Collect server-side gradients\n",
        "        gradients_server = local.get_server_gradients_from_train_server()\n",
        "        if gradients_server:\n",
        "            w_locals_server.append(gradients_server)\n",
        "\n",
        "        # Client evaluation\n",
        "        local.evaluate(net=copy.deepcopy(net_glob_client).to(device), ell=iter)\n",
        "\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "    print(\"------ Federation process at Client-Side ------- \")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    # Aggregate client-side gradients and update net_glob_client\n",
        "    if len(grad_locals_client) > 0:\n",
        "        avg_gradients_client = FedSGD(grad_locals_client)\n",
        "        for name in avg_gradients_client:\n",
        "            avg_gradients_client[name] = avg_gradients_client[name].to(device)\n",
        "        for name, param in net_glob_client.named_parameters():\n",
        "            if name in avg_gradients_client:\n",
        "                param.data = param.data.to(device) - lr * avg_gradients_client[name].to(device)\n",
        "\n",
        "    # Aggregate server-side gradients and update net_glob_server\n",
        "    if len(w_locals_server) > 0:\n",
        "        w_glob_server = FedSGD(w_locals_server)\n",
        "        for name in w_glob_server:\n",
        "            w_glob_server[name] = w_glob_server[name].to(device)\n",
        "        net_glob_server.to(device)\n",
        "        for name, param in net_glob_server.named_parameters():\n",
        "            if name in w_glob_server:\n",
        "                param.data -= lr * w_glob_server[name].to(device)\n",
        "\n",
        "        # Update local server models\n",
        "        net_model_server = [copy.deepcopy(net_glob_server).to(device) for _ in range(num_users)]\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    epoch_times.append(epoch_time)\n",
        "    print(f\"Epoch {iter + 1}/{epochs} - Time taken: {epoch_time:.2f} seconds\")\n",
        "\n",
        "print(\"Training and Evaluation completed!\")\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client2 Train => Local Epoch: 0 \tAcc: 0.410 \tLoss: 1.1012 \tPrecision: 0.319 \tRecall: 0.351 \tAUC: 0.505\n",
            "Client2 Test =>                   \tAcc: 0.501 \tLoss: 1.1887 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.387 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   0, Avg Accuracy 0.410 | Avg Loss 1.101\n",
            " Test: Round   0, Avg Accuracy 0.501 | Avg Loss 1.189\n",
            "==========================================================\n",
            "Client1 Train => Local Epoch: 0 \tAcc: 0.394 \tLoss: 1.1011 \tPrecision: 0.348 \tRecall: 0.338 \tAUC: 0.513\n",
            "Client1 Test =>                   \tAcc: 0.501 \tLoss: 1.1862 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.389 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   0, Avg Accuracy 0.394 | Avg Loss 1.101\n",
            " Test: Round   0, Avg Accuracy 0.501 | Avg Loss 1.186\n",
            "==========================================================\n",
            "Client0 Train => Local Epoch: 0 \tAcc: 0.424 \tLoss: 1.1004 \tPrecision: 0.371 \tRecall: 0.360 \tAUC: 0.511\n",
            "Client0 Test =>                   \tAcc: 0.501 \tLoss: 1.1593 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.410 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   0, Avg Accuracy 0.424 | Avg Loss 1.100\n",
            " Test: Round   0, Avg Accuracy 0.501 | Avg Loss 1.159\n",
            "==========================================================\n",
            "-----------------------------------------------------------\n",
            "------ Federation process at Client-Side ------- \n",
            "-----------------------------------------------------------\n",
            "Epoch 1/80 - Time taken: 22.04 seconds\n",
            "Client0 Train => Local Epoch: 0 \tAcc: 0.419 \tLoss: 1.0939 \tPrecision: 0.381 \tRecall: 0.341 \tAUC: 0.541\n",
            "Client0 Test =>                   \tAcc: 0.501 \tLoss: 1.1256 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.443 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   1, Avg Accuracy 0.419 | Avg Loss 1.094\n",
            " Test: Round   1, Avg Accuracy 0.501 | Avg Loss 1.126\n",
            "==========================================================\n",
            "Client2 Train => Local Epoch: 0 \tAcc: 0.379 \tLoss: 1.1059 \tPrecision: 0.346 \tRecall: 0.366 \tAUC: 0.523\n",
            "Client2 Test =>                   \tAcc: 0.501 \tLoss: 1.1263 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.432 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   1, Avg Accuracy 0.379 | Avg Loss 1.106\n",
            " Test: Round   1, Avg Accuracy 0.501 | Avg Loss 1.126\n",
            "==========================================================\n",
            "Client1 Train => Local Epoch: 0 \tAcc: 0.427 \tLoss: 1.0981 \tPrecision: 0.372 \tRecall: 0.370 \tAUC: 0.512\n",
            "Client1 Test =>                   \tAcc: 0.501 \tLoss: 1.1294 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.436 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   1, Avg Accuracy 0.427 | Avg Loss 1.098\n",
            " Test: Round   1, Avg Accuracy 0.501 | Avg Loss 1.129\n",
            "==========================================================\n",
            "-----------------------------------------------------------\n",
            "------ Federation process at Client-Side ------- \n",
            "-----------------------------------------------------------\n",
            "Epoch 2/80 - Time taken: 21.78 seconds\n",
            "Client2 Train => Local Epoch: 0 \tAcc: 0.385 \tLoss: 1.1008 \tPrecision: 0.328 \tRecall: 0.341 \tAUC: 0.516\n",
            "Client2 Test =>                   \tAcc: 0.501 \tLoss: 1.1258 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.436 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   2, Avg Accuracy 0.385 | Avg Loss 1.101\n",
            " Test: Round   2, Avg Accuracy 0.501 | Avg Loss 1.126\n",
            "==========================================================\n",
            "Client0 Train => Local Epoch: 0 \tAcc: 0.414 \tLoss: 1.0947 \tPrecision: 0.329 \tRecall: 0.342 \tAUC: 0.522\n",
            "Client0 Test =>                   \tAcc: 0.501 \tLoss: 1.1290 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.440 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   2, Avg Accuracy 0.414 | Avg Loss 1.095\n",
            " Test: Round   2, Avg Accuracy 0.501 | Avg Loss 1.129\n",
            "==========================================================\n",
            "Client1 Train => Local Epoch: 0 \tAcc: 0.397 \tLoss: 1.1014 \tPrecision: 0.359 \tRecall: 0.347 \tAUC: 0.506\n",
            "Client1 Test =>                   \tAcc: 0.501 \tLoss: 1.1242 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.423 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   2, Avg Accuracy 0.397 | Avg Loss 1.101\n",
            " Test: Round   2, Avg Accuracy 0.501 | Avg Loss 1.124\n",
            "==========================================================\n",
            "-----------------------------------------------------------\n",
            "------ Federation process at Client-Side ------- \n",
            "-----------------------------------------------------------\n",
            "Epoch 3/80 - Time taken: 22.57 seconds\n",
            "Client0 Train => Local Epoch: 0 \tAcc: 0.401 \tLoss: 1.1042 \tPrecision: 0.331 \tRecall: 0.347 \tAUC: 0.489\n",
            "Client0 Test =>                   \tAcc: 0.501 \tLoss: 1.1235 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.436 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   3, Avg Accuracy 0.401 | Avg Loss 1.104\n",
            " Test: Round   3, Avg Accuracy 0.501 | Avg Loss 1.123\n",
            "==========================================================\n",
            "Client1 Train => Local Epoch: 0 \tAcc: 0.430 \tLoss: 1.1018 \tPrecision: 0.408 \tRecall: 0.381 \tAUC: 0.539\n",
            "Client1 Test =>                   \tAcc: 0.501 \tLoss: 1.1286 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.433 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   3, Avg Accuracy 0.430 | Avg Loss 1.102\n",
            " Test: Round   3, Avg Accuracy 0.501 | Avg Loss 1.129\n",
            "==========================================================\n",
            "Client2 Train => Local Epoch: 0 \tAcc: 0.371 \tLoss: 1.0985 \tPrecision: 0.324 \tRecall: 0.330 \tAUC: 0.516\n",
            "Client2 Test =>                   \tAcc: 0.501 \tLoss: 1.1270 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.442 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   3, Avg Accuracy 0.371 | Avg Loss 1.098\n",
            " Test: Round   3, Avg Accuracy 0.501 | Avg Loss 1.127\n",
            "==========================================================\n",
            "-----------------------------------------------------------\n",
            "------ Federation process at Client-Side ------- \n",
            "-----------------------------------------------------------\n",
            "Epoch 4/80 - Time taken: 23.07 seconds\n",
            "Client1 Train => Local Epoch: 0 \tAcc: 0.391 \tLoss: 1.1066 \tPrecision: 0.331 \tRecall: 0.348 \tAUC: 0.489\n",
            "Client1 Test =>                   \tAcc: 0.501 \tLoss: 1.1324 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.445 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   4, Avg Accuracy 0.391 | Avg Loss 1.107\n",
            " Test: Round   4, Avg Accuracy 0.501 | Avg Loss 1.132\n",
            "==========================================================\n",
            "Client0 Train => Local Epoch: 0 \tAcc: 0.420 \tLoss: 1.1016 \tPrecision: 0.350 \tRecall: 0.355 \tAUC: 0.494\n",
            "Client0 Test =>                   \tAcc: 0.501 \tLoss: 1.1265 \tPrecision: 0.178 \tRecall: 0.333 \tAUC: 0.430 \tF1-Score: 0.232\n",
            "------------------------------------------------\n",
            "------ Federation process at Server-Side ------- \n",
            "------------------------------------------------\n",
            "====================== SERVER V1==========================\n",
            " Train: Round   4, Avg Accuracy 0.420 | Avg Loss 1.102\n",
            " Test: Round   4, Avg Accuracy 0.501 | Avg Loss 1.126\n",
            "==========================================================\n",
            "Client2 Train => Local Epoch: 0 \tAcc: 0.404 \tLoss: 1.0976 \tPrecision: 0.376 \tRecall: 0.358 \tAUC: 0.522\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-8e92fddb1703>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Client training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mgradients_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_glob_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgradients_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mgrad_locals_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ace403a8cc2b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, net)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mlen_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldr_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldr_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0moptimizer_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-ace403a8cc2b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \"\"\"\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2326\u001b[0m                 )\n\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2330\u001b[0m     def reduce(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}