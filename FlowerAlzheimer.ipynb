{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luanmantegazine/FedAlzheimer/blob/main/FlowerAlzheimer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d3Exonuq6qst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9239ae-3126-4cbd-ba94-0068d8b602be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.6/617.6 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.7/66.7 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pyopenssl 24.2.1 requires cryptography<44,>=41.0.5, but you have cryptography 44.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install \"flwr[simulation]>=1.20.0\" \"torchvision>=0.15\" \"torch>=2.0\" \"torchmetrics>=1.4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rKZf3N4n4rjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a41f972c-d43d-4ecc-9756-1bcb3b3caa15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, math, random\n",
        "from contextlib import nullcontext\n",
        "from collections import Counter, OrderedDict\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "import torchmetrics\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.client import ClientApp\n",
        "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
        "from flwr.server.strategy import FedAvgM\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr.common import NDArrays, ndarrays_to_parameters, Context\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ.pop(\"NVIDIA_VISIBLE_DEVICES\", None)\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
      ],
      "metadata": {
        "id": "B-hDgoe2YYW3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPeZNGj_7hcm"
      },
      "source": [
        "Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cQI1XkY-7l0Q"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "\n",
        "  data_path: str = \"/content/drive/MyDrive/TCC - Grupo SLD/Projeto 2/ADNI\"\n",
        "  input_size: int = 224\n",
        "  grayscale3: bool = True\n",
        "\n",
        "  # FL\n",
        "  num_clients: int = 3\n",
        "  num_rounds: int = 10\n",
        "  seed: int = 1234\n",
        "\n",
        "  # particionamento\n",
        "  partition_strategy: str = \"dirichlet\"\n",
        "  dirichlet_alpha: float = 0.5\n",
        "\n",
        "  # treino local\n",
        "  batch_size: int = 32\n",
        "  local_epochs: int = 2\n",
        "  learning_rate_head: float = 5e-4\n",
        "  learning_rate_backbone: float = 1e-4\n",
        "  weight_decay: float = 1e-4\n",
        "  optimizer: str = \"sgd\"  # \"sgd\" ou \"adamw\"\n",
        "  momentum: float = 0.9\n",
        "  grad_clip_norm: float = 1.0\n",
        "\n",
        "  # fine-tuning gradual\n",
        "  head_only_first_rounds: int = 1  # rounds iniciais treinando só a cabeça\n",
        "  dropout: float = 0.3\n",
        "  label_smoothing: float = 0.05\n",
        "\n",
        "  # augmentação\n",
        "  use_color_jitter: bool = True\n",
        "  mixup_alpha: float = 0.2  # 0.0 desliga MixUp\n",
        "\n",
        "  # loss\n",
        "  use_focal_loss: bool = False\n",
        "  focal_gamma: float = 2.0\n",
        "\n",
        "  # scheduler\n",
        "  use_cosine_warmup: bool = True\n",
        "  warmup_epochs: int = 2\n",
        "\n",
        "  # EMA\n",
        "  use_ema: bool = True\n",
        "  ema_decay: float = 0.999\n",
        "\n",
        "  # TTA (test-time augmentation)\n",
        "  tta_hflip: bool = True\n",
        "\n",
        "  # strategy do servidor\n",
        "  server_strategy: str = \"fedavgm\"  # \"fedavgm\" ou \"fedadam\"\n",
        "  # FedAvgM\n",
        "  server_learning_rate: float = 1e-3\n",
        "  server_momentum: float = 0.9\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v6aTIYn-_KCg"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "def build_transforms():\n",
        "    tr = [\n",
        "        transforms.Resize((max(256, cfg.input_size), max(256, cfg.input_size))),\n",
        "        transforms.RandomResizedCrop(cfg.input_size, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "    ]\n",
        "    if cfg.grayscale3:\n",
        "        tr.insert(2, transforms.Grayscale(num_output_channels=3))\n",
        "    if cfg.use_color_jitter:\n",
        "        tr.insert(3, transforms.ColorJitter(brightness=0.2, contrast=0.2))\n",
        "    tr += [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        "    train_transform = transforms.Compose(tr)\n",
        "\n",
        "    te = [transforms.Resize((cfg.input_size, cfg.input_size))]\n",
        "    if cfg.grayscale3:\n",
        "        te.append(transforms.Grayscale(num_output_channels=3))\n",
        "    te += [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ]\n",
        "    test_transform = transforms.Compose(te)\n",
        "    return train_transform, test_transform\n",
        "\n",
        "def partition_dirichlet(labels_all: List[int], idxs: np.ndarray, num_clients: int,\n",
        "                        alpha: float, seed: int, min_size: int = 10):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    labels = np.array([labels_all[i] for i in idxs])\n",
        "    client_indices = {i: [] for i in range(num_clients)}\n",
        "    min_client_size = 0\n",
        "    # Garante que todos os clientes recebem exemplos\n",
        "    while min_client_size < min_size:\n",
        "        client_indices = {i: [] for i in range(num_clients)}\n",
        "        for c in np.unique(labels):\n",
        "            idx_c = idxs[labels == c]\n",
        "            rng.shuffle(idx_c)\n",
        "            proportions = rng.dirichlet(alpha=np.repeat(alpha, num_clients))\n",
        "            proportions = proportions / proportions.sum()\n",
        "            splits = (np.cumsum(proportions) * len(idx_c)).astype(int)[:-1]\n",
        "            chunks = np.split(idx_c, splits)\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                client_indices[i].extend(chunk.tolist())\n",
        "        sizes = [len(client_indices[i]) for i in range(num_clients)]\n",
        "        min_client_size = min(sizes) if sizes else 0\n",
        "    return {i: np.array(v) for i, v in client_indices.items()}\n",
        "\n",
        "def make_weights_for_balanced_classes(indices: List[int], imagefolder: datasets.ImageFolder, num_classes: int):\n",
        "    labels = [imagefolder.samples[i][1] for i in indices]\n",
        "    cnt = Counter(labels)\n",
        "    class_weight = {c: len(labels) / (num_classes * cnt[c]) if cnt[c] > 0 else 0 for c in range(num_classes)}\n",
        "    sample_weights = [class_weight[lbl] for lbl in labels]\n",
        "    return torch.DoubleTensor(sample_weights)\n",
        "\n",
        "def mixup(x, y, alpha=0.2):\n",
        "    if alpha is None or alpha <= 0:\n",
        "        return x, (y, y), 1.0\n",
        "    lam = float(np.random.beta(alpha, alpha))\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[idx]\n",
        "    return mixed_x, (y, y[idx]), lam\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=None, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.gamma, self.alpha, self.reduction = gamma, alpha, reduction\n",
        "        self.ce = nn.CrossEntropyLoss(weight=alpha, reduction=\"none\")\n",
        "    def forward(self, logits, target):\n",
        "        ce = self.ce(logits, target)  # [N]\n",
        "        pt = torch.softmax(logits, dim=1).gather(1, target.view(-1, 1)).squeeze(1)\n",
        "        loss = (1 - pt).pow(self.gamma) * ce\n",
        "        return loss.mean() if self.reduction == \"mean\" else loss.sum()\n",
        "\n",
        "def build_model(num_classes: int):\n",
        "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(nn.Dropout(p=cfg.dropout), nn.Linear(in_features, num_classes))\n",
        "    return model\n",
        "\n",
        "def get_params(model: nn.Module):\n",
        "    return [v.detach().cpu().numpy() for _, v in model.state_dict().items()]\n",
        "\n",
        "def set_params(model: nn.Module, params: NDArrays):\n",
        "    state_dict = model.state_dict()\n",
        "    new_state_dict = OrderedDict({k: torch.tensor(v) for k, v in zip(state_dict.keys(), params)})\n",
        "    model.load_state_dict(new_state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sOeCv7_r_MR2"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Metrics:\n",
        "    loss: float\n",
        "    accuracy: float\n",
        "    precision: float\n",
        "    recall: float\n",
        "    f1: float\n",
        "    auc: float\n",
        "\n",
        "def evaluate_model(model: nn.Module, loader: DataLoader, device: torch.device, num_classes: int) -> Metrics:\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses, logits_list, labels_list = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out_logits = model(x)\n",
        "            if cfg.tta_hflip:\n",
        "                out_logits = out_logits + model(torch.flip(x, dims=[3]))\n",
        "                out_logits = out_logits / 2.0\n",
        "            loss = criterion(out_logits, y)\n",
        "            losses.append(loss.item())\n",
        "            logits_list.append(out_logits.cpu())\n",
        "            labels_list.append(y.cpu())\n",
        "\n",
        "    logits = torch.cat(logits_list) if logits_list else torch.zeros((0, num_classes))\n",
        "    labels = torch.cat(labels_list) if labels_list else torch.zeros((0,), dtype=torch.long)\n",
        "    if logits.shape[0] == 0:\n",
        "        return Metrics(0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
        "\n",
        "    preds = logits.argmax(dim=1)\n",
        "    prob = F.softmax(logits, dim=1)\n",
        "\n",
        "    try:\n",
        "        auc_score = torchmetrics.functional.auroc(prob, labels, task=\"multiclass\", num_classes=num_classes).item()\n",
        "    except Exception:\n",
        "        auc_score = 0.0\n",
        "\n",
        "    return Metrics(\n",
        "        loss=float(np.mean(losses)),\n",
        "        accuracy=torchmetrics.functional.accuracy(preds, labels, task=\"multiclass\", num_classes=num_classes).item(),\n",
        "        precision=torchmetrics.functional.precision(preds, labels, average=\"macro\", task=\"multiclass\", num_classes=num_classes, zero_division=0).item(),\n",
        "        recall=torchmetrics.functional.recall(preds, labels, average=\"macro\", task=\"multiclass\", num_classes=num_classes, zero_division=0).item(),\n",
        "        f1=torchmetrics.functional.f1_score(preds, labels, average=\"macro\", task=\"multiclass\", num_classes=num_classes, zero_division=0).item(),\n",
        "        auc=auc_score,\n",
        "    )\n",
        "\n",
        "class EMA:\n",
        "    def __init__(self, model: nn.Module, decay: float = 0.999):\n",
        "        self.decay = decay\n",
        "        self.shadow = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n",
        "        self.backup = {}\n",
        "    def update(self, model: nn.Module):\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in self.shadow and p.requires_grad:\n",
        "                self.shadow[n].mul_(self.decay).add_(p.detach(), alpha=1.0 - self.decay)\n",
        "    def apply_shadow(self, model: nn.Module):\n",
        "        self.backup = {}\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in self.shadow and p.requires_grad:\n",
        "                self.backup[n] = p.detach().clone()\n",
        "                p.data.copy_(self.shadow[n].data)\n",
        "    def restore(self, model: nn.Module):\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in self.backup and p.requires_grad:\n",
        "                p.data.copy_(self.backup[n].data)\n",
        "        self.backup = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AKu6ib4u_QQE"
      },
      "outputs": [],
      "source": [
        "seed_everything(cfg.seed)\n",
        "device = get_device()\n",
        "train_tf, test_tf = build_transforms()\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=cfg.data_path)\n",
        "labels_all = [lbl for _, lbl in full_dataset.samples]\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "idx_all = np.arange(len(full_dataset))\n",
        "from sklearn.model_selection import train_test_split\n",
        "idx_train, idx_test = train_test_split(\n",
        "    idx_all, test_size=0.2, stratify=labels_all, random_state=cfg.seed\n",
        ")\n",
        "\n",
        "class TransformingSubset(Dataset):\n",
        "    def __init__(self, subset, transform):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.subset[idx]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "test_dataset: Dataset = TransformingSubset(Subset(full_dataset, idx_test), test_tf)\n",
        "\n",
        "# particionamento (Dirichlet) no conjunto de treino\n",
        "parts_train = partition_dirichlet(labels_all, idx_train, cfg.num_clients, cfg.dirichlet_alpha, cfg.seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cseXbgjA_Yv-"
      },
      "outputs": [],
      "source": [
        "seed_everything(cfg.seed)\n",
        "device = get_device()\n",
        "\n",
        "train_tf, test_tf = build_transforms()\n",
        "full_dataset = datasets.ImageFolder(root=cfg.data_path)\n",
        "labels_all = [lbl for _, lbl in full_dataset.samples]\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "idx_all = np.arange(len(full_dataset))\n",
        "idx_train, idx_test = train_test_split(\n",
        "    idx_all, test_size=0.2, stratify=labels_all, random_state=cfg.seed\n",
        ")\n",
        "\n",
        "class TransformingSubset(Dataset):\n",
        "    def __init__(self, subset, transform):\n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return len(self.subset)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.subset[idx]\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "test_dataset: Dataset = TransformingSubset(Subset(full_dataset, idx_test), test_tf)\n",
        "parts_train = partition_dirichlet(labels_all, idx_train, cfg.num_clients, cfg.dirichlet_alpha, cfg.seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AlzheimerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid: int, full_dataset, train_idx, test_idx, num_classes,\n",
        "                 lr_head, lr_backbone, batch_size, local_epochs, device):\n",
        "        self.cid = cid\n",
        "        self.num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.local_epochs = local_epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        sub_train = TransformingSubset(Subset(full_dataset, train_idx), train_tf)\n",
        "        sub_test  = TransformingSubset(Subset(full_dataset, test_idx),  test_tf)\n",
        "\n",
        "\n",
        "        sampler = None\n",
        "        base_subset = sub_train.subset\n",
        "        if isinstance(base_subset, Subset) and isinstance(base_subset.dataset, datasets.ImageFolder) and len(base_subset.indices) > 0:\n",
        "            weights = make_weights_for_balanced_classes(base_subset.indices, base_subset.dataset, num_classes)\n",
        "            sampler = WeightedRandomSampler(weights, num_samples=len(base_subset.indices), replacement=True)\n",
        "\n",
        "        self.train_loader = DataLoader(sub_train, batch_size=batch_size, shuffle=(sampler is None),\n",
        "                                       sampler=sampler, num_workers=0, persistent_workers=False, pin_memory=False)\n",
        "        self.test_loader  = DataLoader(sub_test,  batch_size=batch_size, shuffle=False,\n",
        "                                       num_workers=0, persistent_workers=False, pin_memory=False)\n",
        "\n",
        "        self.model = build_model(num_classes).to(self.device)\n",
        "\n",
        "        if cfg.use_focal_loss:\n",
        "            self.criterion = FocalLoss(gamma=cfg.focal_gamma).to(self.device)\n",
        "        else:\n",
        "            self.criterion = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing).to(self.device)\n",
        "\n",
        "        head_params, backbone_params = [], []\n",
        "        for n, p in self.model.named_parameters():\n",
        "            (head_params if n.startswith(\"fc.\") else backbone_params).append(p)\n",
        "\n",
        "        if cfg.optimizer.lower() == \"sgd\":\n",
        "            self.optimizer = torch.optim.SGD([\n",
        "                {\"params\": backbone_params, \"lr\": lr_backbone, \"weight_decay\": cfg.weight_decay, \"momentum\": cfg.momentum},\n",
        "                {\"params\": head_params,     \"lr\": lr_head,     \"weight_decay\": cfg.weight_decay, \"momentum\": cfg.momentum},\n",
        "            ])\n",
        "        else:\n",
        "            self.optimizer = torch.optim.AdamW([\n",
        "                {\"params\": backbone_params, \"lr\": lr_backbone, \"weight_decay\": cfg.weight_decay},\n",
        "                {\"params\": head_params,     \"lr\": lr_head,     \"weight_decay\": cfg.weight_decay},\n",
        "            ])\n",
        "\n",
        "        if cfg.use_cosine_warmup:\n",
        "            def lr_lambda(ep):\n",
        "                if ep < cfg.warmup_epochs:\n",
        "                    return (ep + 1) / max(1, cfg.warmup_epochs)\n",
        "                t = (ep - cfg.warmup_epochs) / max(1, self.local_epochs - cfg.warmup_epochs)\n",
        "                return 0.5 * (1 + math.cos(math.pi * t))\n",
        "            self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lr_lambda)\n",
        "        else:\n",
        "            self.scheduler = None\n",
        "\n",
        "        self.ema = EMA(self.model, decay=cfg.ema_decay) if cfg.use_ema else None\n",
        "\n",
        "    def _freeze_backbone(self, freeze: bool = True):\n",
        "        for n, p in self.model.named_parameters():\n",
        "            if not n.startswith(\"fc.\"):\n",
        "                p.requires_grad = not freeze\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_params(self.model)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_params(self.model, parameters)\n",
        "\n",
        "        current_round = int(config.get(\"round\", 1)) if config else 1\n",
        "        head_only = current_round <= cfg.head_only_first_rounds\n",
        "        self._freeze_backbone(head_only)\n",
        "\n",
        "        epochs = int(config.get(\"local_epochs\", self.local_epochs)) if config else self.local_epochs\n",
        "        amp_ctx = nullcontext()  # CPU: sem autocast\n",
        "\n",
        "        self.model.train()\n",
        "        for ep in range(epochs):\n",
        "            for x, y in self.train_loader:\n",
        "                x, y = x.to(self.device), y.to(self.device)\n",
        "                self.optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "                if cfg.mixup_alpha and cfg.mixup_alpha > 0:\n",
        "                    x, (y_a, y_b), lam = mixup(x, y, alpha=cfg.mixup_alpha)\n",
        "                    with amp_ctx:\n",
        "                        logits = self.model(x)\n",
        "                        loss = lam * self.criterion(logits, y_a) + (1 - lam) * self.criterion(logits, y_b)\n",
        "                else:\n",
        "                    with amp_ctx:\n",
        "                        logits = self.model(x)\n",
        "                        loss = self.criterion(logits, y)\n",
        "\n",
        "                loss.backward()\n",
        "                if cfg.grad_clip_norm and cfg.grad_clip_norm > 0:\n",
        "                    nn.utils.clip_grad_norm_(self.model.parameters(), cfg.grad_clip_norm)\n",
        "                self.optimizer.step()\n",
        "\n",
        "                if self.ema:\n",
        "                    self.ema.update(self.model)\n",
        "\n",
        "            if self.scheduler:\n",
        "                self.scheduler.step()\n",
        "\n",
        "        if self.ema:\n",
        "            self.ema.apply_shadow(self.model)\n",
        "        m = evaluate_model(self.model, self.test_loader, self.device, self.num_classes)\n",
        "        if self.ema:\n",
        "            self.ema.restore(self.model)\n",
        "\n",
        "        return get_params(self.model), len(self.train_loader.dataset), {\n",
        "            \"accuracy_local\": m.accuracy, \"f1_local\": m.f1\n",
        "        }\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_params(self.model, parameters)\n",
        "        if self.ema:\n",
        "            self.ema.apply_shadow(self.model)\n",
        "        m = evaluate_model(self.model, self.test_loader, self.device, self.num_classes)\n",
        "        if self.ema:\n",
        "            self.ema.restore(self.model)\n",
        "        return m.loss, len(self.test_loader.dataset), {\"accuracy\": m.accuracy, \"f1\": m.f1}\n",
        "\n"
      ],
      "metadata": {
        "id": "JQWureuV5mVq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluate_fn(test_dataset: Dataset, batch_size: int, num_classes: int, device: torch.device):\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    def evaluate(server_round: int, parameters: NDArrays, config_server: Dict[str, float]):\n",
        "        model = build_model(num_classes).to(device)\n",
        "        set_params(model, parameters)\n",
        "        m = evaluate_model(model, test_loader, device, num_classes)\n",
        "        return m.loss, {\"accuracy\": m.accuracy, \"precision\": m.precision, \"recall\": m.recall, \"f1\": m.f1, \"auc\": m.auc}\n",
        "    return evaluate\n",
        "\n",
        "def weighted_average(client_metrics: List[Tuple[int, Dict[str, float]]]) -> Dict[str, float]:\n",
        "    if not client_metrics:\n",
        "        return {}\n",
        "    total = sum(n for n, _ in client_metrics)\n",
        "    if total == 0:\n",
        "        keys0 = list(client_metrics[0][1].keys())\n",
        "        return {k: 0.0 for k in keys0}\n",
        "    all_keys = set().union(*(m.keys() for _, m in client_metrics))\n",
        "    return {k: sum(n * m.get(k, 0.0) for n, m in client_metrics) / total for k in all_keys}\n"
      ],
      "metadata": {
        "id": "SkiI5vTezOCF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(context: Context):\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"  # reforça CPU nos atores\n",
        "    try:\n",
        "        torch.set_num_threads(1)\n",
        "    except Exception:\n",
        "        pass\n",
        "    cid = int(context.node_id) % cfg.num_clients\n",
        "    train_idx = parts_train[cid]\n",
        "    return AlzheimerClient(\n",
        "        cid=cid,\n",
        "        full_dataset=full_dataset,\n",
        "        train_idx=train_idx,\n",
        "        test_idx=idx_test,\n",
        "        num_classes=num_classes,\n",
        "        lr_head=cfg.learning_rate_head,\n",
        "        lr_backbone=cfg.learning_rate_backbone,\n",
        "        batch_size=cfg.batch_size,\n",
        "        local_epochs=cfg.local_epochs,\n",
        "        device=device,\n",
        "    ).to_client()\n",
        "\n",
        "client_app = ClientApp(client_fn)\n",
        "\n",
        "# ====== ServerApp ======\n",
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    server_cfg = ServerConfig(num_rounds=cfg.num_rounds)\n",
        "    initial_parameters = ndarrays_to_parameters(get_params(build_model(num_classes)))\n",
        "    strategy = FedAvgM(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_available_clients=cfg.num_clients,\n",
        "        evaluate_fn=get_evaluate_fn(test_dataset, cfg.batch_size, num_classes, device),\n",
        "        on_fit_config_fn=lambda rnd: {\"local_epochs\": cfg.local_epochs, \"round\": rnd},\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,\n",
        "        server_learning_rate=cfg.server_learning_rate,\n",
        "        server_momentum=cfg.server_momentum,\n",
        "        initial_parameters=initial_parameters,\n",
        "    )\n",
        "    # Compat com versões (server_config vs config)\n",
        "    try:\n",
        "        return ServerAppComponents(strategy=strategy, server_config=server_cfg)\n",
        "    except TypeError:\n",
        "        return ServerAppComponents(strategy=strategy, config=server_cfg)\n",
        "\n",
        "server_app = ServerApp(server_fn=server_fn)\n"
      ],
      "metadata": {
        "id": "2lC_0lWszQy4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Apps prontos. Iniciando simulação...\")\n",
        "history = run_simulation(\n",
        "    server_app=server_app,\n",
        "    client_app=client_app,\n",
        "    num_supernodes=cfg.num_clients,\n",
        "    backend_config={\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}},\n",
        ")\n",
        "print(\"Simulação concluída.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4PmzXlkQdyc",
        "outputId": "279a3605-f3ce-42dc-9587-156f580c21e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apps prontos. Iniciando simulação...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 205MB/s]\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py:344: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(np_img, \"RGB\")\n",
            "\u001b[36m(pid=1665)\u001b[0m 2025-08-13 17:21:49.907695: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1665)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=1665)\u001b[0m E0000 00:00:1755105709.973253    1665 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1665)\u001b[0m E0000 00:00:1755105709.992572    1665 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1665)\u001b[0m W0000 00:00:1755105710.035032    1665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1665)\u001b[0m W0000 00:00:1755105710.036181    1665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1665)\u001b[0m W0000 00:00:1755105710.036188    1665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=1665)\u001b[0m W0000 00:00:1755105710.036192    1665 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 1.1130734384059906, {'accuracy': 0.47706422209739685, 'precision': 0.2714884877204895, 'recall': 0.3300139904022217, 'f1': 0.23093049228191376, 'auc': 0.4617125689983368}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=1665)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py:344: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "\u001b[36m(ClientAppActor pid=1665)\u001b[0m   img = Image.fromarray(np_img, \"RGB\")\n",
            "\u001b[36m(ClientAppActor pid=1665)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:324: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "\u001b[36m(ClientAppActor pid=1665)\u001b[0m   return Image.fromarray(npimg, mode=mode)\n",
            "\u001b[36m(pid=1670)\u001b[0m 2025-08-13 17:21:50.099354: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=1670)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=1670)\u001b[0m E0000 00:00:1755105710.162185    1670 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=1670)\u001b[0m E0000 00:00:1755105710.180583    1670 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=1670)\u001b[0m W0000 00:00:1755105710.218036    1670 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}