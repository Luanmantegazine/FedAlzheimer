{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Luanmantegazine/TF/blob/main/FED_ADNIData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "seGN9Ju7v7w-",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:45:56.686070Z",
     "start_time": "2024-10-07T19:45:31.675762Z"
    }
   },
   "source": [
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib as plt\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlknLHbixiCq"
   },
   "source": [
    "#Definindo o número de clientes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HtpTQpfMxhka",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b9877add-b320-4f89-e65b-53f73d5f1e20",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:46:05.441136Z",
     "start_time": "2024-10-07T19:46:05.403083Z"
    }
   },
   "source": [
    "num_users = 2\n",
    "num_classes =  4\n",
    "epochs = 100\n",
    "frac = 1\n",
    "lr= 0.0001\n",
    "batch_size = 64\n",
    "class_weights = torch.tensor([1/717, 1/52, 1/2560, 1/1792], dtype=torch.float32)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIgHK_5Cx0Xo"
   },
   "source": [
    "#Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8TDdVPq2x4cf",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:46:10.046762Z",
     "start_time": "2024-10-07T19:46:09.987699Z"
    }
   },
   "source": [
    "data_path = '/Users/luanr/pycharm/TF/Alzheimers Dataset'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=data_path + '/train',\n",
    "    transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=data_path + '/test',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T19:48:11.340023Z",
     "start_time": "2024-10-07T19:46:13.152895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_smote_to_dataset(dataset):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for image, label in dataset:\n",
    "        data.append(image.numpy().flatten())\n",
    "        labels.append(label)\n",
    "\n",
    "    smote = SMOTE(random_state=SEED)\n",
    "    data_resampled, labels_resampled = smote.fit_resample(np.array(data), np.array(labels))\n",
    "    \n",
    "    return data_resampled, labels_resampled\n",
    "\n",
    "train_data_resampled, train_labels_resampled = apply_smote_to_dataset(train_dataset)\n",
    "\n",
    "class SMOTEDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx].reshape(224, 224, 3)\n",
    "        label = self.labels[idx]\n",
    "        image = np.uint8(image * 255)\n",
    "        image = Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "smote_train_dataset = SMOTEDataset(train_data_resampled, train_labels_resampled,\n",
    "                                   transform=transforms.Compose([\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.RandomVerticalFlip(),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                                       transforms.RandomGrayscale(p=0.1),\n",
    "                                       transforms.RandomPerspective(),\n",
    "                                       transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "                                       transforms.ToTensor(),  # ToTensor será aplicado aqui\n",
    "                                       transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                                   ]))\n",
    "\n",
    "\n",
    "train_loader = DataLoader(smote_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:21.433843Z",
     "start_time": "2024-10-07T19:49:21.346301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_samples_per_class_in_smote_dataset(smote_dataset, num_classes):\n",
    "    class_counts = {i: 0 for i in range(num_classes)}  \n",
    "    for label in smote_dataset.labels:\n",
    "        class_counts[label] += 1\n",
    "    return class_counts\n",
    "\n",
    "def count_samples_per_class_in_imagefolder(dataset):\n",
    "    class_counts = {}\n",
    "    for class_idx, class_name in enumerate(dataset.classes):\n",
    "        class_counts[class_name] = len([label for _, label in dataset.samples if label == class_idx])\n",
    "    return class_counts\n",
    "\n",
    "print(\"Número de amostras por classe no treino (após SMOTE):\")\n",
    "train_class_counts = count_samples_per_class_in_smote_dataset(smote_train_dataset, num_classes=num_classes)\n",
    "for class_idx, count in train_class_counts.items():\n",
    "    print(f\"Classe {class_idx}: {count}\")\n",
    "\n",
    "print(\"Número de amostras por classe no teste:\")\n",
    "test_class_counts = count_samples_per_class_in_imagefolder(test_dataset)\n",
    "for class_name, count in test_class_counts.items():\n",
    "    print(f\"{class_name}: {count}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras por classe no treino (após SMOTE):\n",
      "Classe 0: 2560\n",
      "Classe 1: 2560\n",
      "Classe 2: 2560\n",
      "Classe 3: 2560\n",
      "Número de amostras por classe no teste:\n",
      "MildDemented: 179\n",
      "ModerateDemented: 12\n",
      "NonDemented: 640\n",
      "VeryMildDemented: 448\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzTpOB0SyjLK"
   },
   "source": "#Definindo o treinamento dos clientes"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_Xcv6TMcynpJ",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:26.603179Z",
     "start_time": "2024-10-07T19:49:26.291781Z"
    }
   },
   "source": [
    "class ResNet50_client_side(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50_client_side, self).__init__()\n",
    "        self.layer1 = nn.Sequential (\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        self.layer2 = self._make_layer(64, 64, 3)\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, blocks):\n",
    "        layers = []\n",
    "        layers.append(self._make_bottleneck(in_planes, out_planes, stride=1))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(self._make_bottleneck(out_planes * 4, out_planes, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_bottleneck(self, in_planes, planes, stride=1):\n",
    "        expansion = 4\n",
    "        out_planes = planes * expansion\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, planes, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(planes, out_planes, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual1 = self.layer1(x)\n",
    "        out1 = self.layer2(residual1)\n",
    "        out1 = F.relu(out1) if out1.size(1) == residual1.size(1) else nn.Conv2d(out1.size(1), residual1.size(1), kernel_size=1, bias=False).to(out1.device)(out1)\n",
    "        out1 += residual1\n",
    "        residual2 = F.relu(out1)\n",
    "        return residual2\n",
    "\n",
    "net_glob_client = ResNet50_client_side()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net_glob_client = nn.DataParallel(net_glob_client)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPhaspYryuye"
   },
   "source": [
    "#Definindo o treinamento do servidor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LapoJhY6yq28",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:29.755614Z",
     "start_time": "2024-10-07T19:49:29.614885Z"
    }
   },
   "source": [
    "class Baseblock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, input_planes, planes, stride=1, dim_change=None):\n",
    "        super(Baseblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_planes, planes, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dim_change = dim_change\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = F.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.bn3(self.conv3(output))\n",
    "\n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "\n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class ResNet50_server_side(nn.Module):\n",
    "    def __init__(self, block, num_layers, num_classes=4):\n",
    "        super(ResNet50_server_side, self).__init__()\n",
    "        self.input_planes = 64\n",
    "        self.conv1 = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, num_layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        dim_change = None\n",
    "        if stride != 1 or self.input_planes != planes * block.expansion:\n",
    "            dim_change = nn.Sequential(\n",
    "                nn.Conv2d(self.input_planes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.input_planes, planes, stride, dim_change))\n",
    "        self.input_planes = planes * block.expansion\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.input_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net_glob_server = ResNet50_server_side(Baseblock, [3, 4, 6, 3], num_classes=4)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net_glob_server = nn.DataParallel(net_glob_server)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jiPpKWagy5OH",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:30.537102Z",
     "start_time": "2024-10-07T19:49:30.526695Z"
    }
   },
   "source": [
    "batch_acc_train = []\n",
    "batch_loss_train = []\n",
    "batch_precision_train = []\n",
    "batch_recall_train = []\n",
    "acc_train_collect_user = []\n",
    "loss_train_collect_user = []\n",
    "loss_test_collect_user = []\n",
    "batch_auc_train = []\n",
    "batch_acc_test = []\n",
    "batch_loss_test = []\n",
    "batch_prec_test = []\n",
    "batch_recall_test = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r48wsNx9y7VM",
    "ExecuteTime": {
     "end_time": "2024-10-07T20:03:55.074329Z",
     "start_time": "2024-10-07T20:03:53.189535Z"
    }
   },
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg\n",
    "\n",
    "def calculate_metrics(fx, y, num_classes):\n",
    "    preds = fx.argmax(dim=1)\n",
    "    accuracy = torchmetrics.functional.accuracy(preds, y, task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    precision = precision_score(y.cpu(), preds.cpu(), average='weighted', zero_division=0)\n",
    "    recall = recall_score(y.cpu(), preds.cpu(), average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y.cpu(), preds.cpu(), average='weighted', zero_division=0)\n",
    "    \n",
    "    auc = torchmetrics.functional.auroc(F.softmax(fx, dim=1), y, task='multiclass', num_classes=num_classes)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "w_glob_server = net_glob_server.state_dict()\n",
    "w_locals_server = []\n",
    "\n",
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "\n",
    "net_model_server = [ResNet50_server_side(Baseblock, [3, 4, 6, 3], num_classes) for i in range(num_users)]\n",
    "\n",
    "net_server = copy.deepcopy(net_model_server[0]).to(device)\n",
    "optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ybaVUIqZy-1j",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:31.884576Z",
     "start_time": "2024-10-07T19:49:31.877793Z"
    }
   },
   "source": [
    "def train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch, num_classes=4):\n",
    "    global net_model_server, criterion, optimizer_server, device\n",
    "    global batch_acc_train, batch_loss_train, batch_precision_train, batch_recall_train, batch_auc_train\n",
    "    global l_epoch_check, fed_check, loss_train_collect, acc_train_collect, count1\n",
    "    global acc_avg_all_user_train, loss_avg_all_user_train, idx_collect, w_locals_server, w_glob_server, net_server\n",
    "    global loss_train_collect_user, acc_train_collect_user, lr\n",
    "\n",
    "    net_server = net_model_server[idx].to(device)\n",
    "    net_server.train()\n",
    "    optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr)\n",
    "\n",
    "    optimizer_server.zero_grad()\n",
    "    fx_client = fx_client.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    fx_server = net_server(fx_client)\n",
    "    loss = criterion(fx_server, y)\n",
    "    acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes)\n",
    "\n",
    "    loss.backward()\n",
    "    dfx_client = fx_client.grad.clone().detach()\n",
    "    optimizer_server.step()\n",
    "\n",
    "    batch_loss_train.append(loss.item())\n",
    "    batch_acc_train.append(acc.item())\n",
    "    batch_precision_train.append(precision.item())\n",
    "    batch_recall_train.append(recall.item())\n",
    "    batch_auc_train.append(auc.item())\n",
    "\n",
    "    net_model_server[idx] = net_server\n",
    "\n",
    "    count1 += 1\n",
    "    if count1 == len_batch:\n",
    "        acc_avg_train = sum(batch_acc_train) / len(batch_acc_train)\n",
    "        loss_avg_train = sum(batch_loss_train) / len(batch_loss_train)\n",
    "        precision_avg_train = sum(batch_precision_train) / len(batch_precision_train)\n",
    "        recall_avg_train = sum(batch_recall_train) / len(batch_recall_train)\n",
    "        auc_avg_train = sum(batch_auc_train) / len(batch_auc_train)\n",
    "\n",
    "        batch_acc_train.clear()\n",
    "        batch_loss_train.clear()\n",
    "        batch_precision_train.clear()\n",
    "        batch_recall_train.clear()\n",
    "        batch_auc_train.clear()\n",
    "        count1 = 0\n",
    "\n",
    "        print(f'Client{idx} Train => Local Epoch: {l_epoch_count} \\tAcc: {acc_avg_train:.3f} \\tLoss: {loss_avg_train:.4f} \\tPrecision: {precision_avg_train:.3f} \\tRecall: {recall_avg_train:.3f} \\tAUC: {auc_avg_train:.3f}')\n",
    "\n",
    "        w_server = net_server.state_dict()\n",
    "\n",
    "        if l_epoch_count == l_epoch - 1:\n",
    "            l_epoch_check = True\n",
    "            w_locals_server.append(copy.deepcopy(w_server))\n",
    "\n",
    "            acc_avg_train_all = acc_avg_train\n",
    "            loss_avg_train_all = loss_avg_train\n",
    "\n",
    "            loss_train_collect_user.append(loss_avg_train_all)\n",
    "            acc_train_collect_user.append(acc_avg_train_all)\n",
    "\n",
    "            if idx not in idx_collect:\n",
    "                idx_collect.append(idx)\n",
    "\n",
    "        if len(idx_collect) == num_users:\n",
    "            fed_check = True\n",
    "            w_glob_server = FedAvg(w_locals_server)\n",
    "            net_glob_server.load_state_dict(w_glob_server)\n",
    "            net_model_server = [copy.deepcopy(net_glob_server) for _ in range(num_users)]\n",
    "            w_locals_server.clear()\n",
    "            idx_collect.clear()\n",
    "\n",
    "            acc_avg_all_user_train = sum(acc_train_collect_user) / len(acc_train_collect_user)\n",
    "            loss_avg_all_user_train = sum(loss_train_collect_user) / len(loss_train_collect_user)\n",
    "\n",
    "            loss_train_collect.append(loss_avg_all_user_train)\n",
    "            acc_train_collect.append(acc_avg_all_user_train)\n",
    "\n",
    "            acc_train_collect_user.clear()\n",
    "            loss_train_collect_user.clear()\n",
    "\n",
    "    return dfx_client"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-azC4sjfzBte",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:32.566017Z",
     "start_time": "2024-10-07T19:49:32.552583Z"
    }
   },
   "source": [
    "def evaluate_server(fx_client, y, idx, len_batch, ell, num_classes=4):\n",
    "    global net_model_server, criterion, batch_acc_test, batch_loss_test, check_fed, net_server, net_glob_server\n",
    "    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, w_glob_server, l_epoch_check, fed_check\n",
    "    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n",
    "\n",
    "    batch_precision_test = []\n",
    "    acc_test_collect_user = []\n",
    "    batch_recall_test = []\n",
    "    batch_auc_test = []\n",
    "    batch_f1_test = []\n",
    "\n",
    "    net = copy.deepcopy(net_model_server[idx]).to(device)\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fx_client = fx_client.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        fx_server = net(fx_client)\n",
    "        loss = criterion(fx_server, y)\n",
    "\n",
    "        acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes)\n",
    "\n",
    "        batch_loss_test.append(loss.item())\n",
    "        batch_acc_test.append(acc.item())\n",
    "        batch_precision_test.append(precision.item())\n",
    "        batch_recall_test.append(recall.item())\n",
    "        batch_auc_test.append(auc.item())\n",
    "        batch_f1_test.append(f1.item())\n",
    "\n",
    "        count2 += 1\n",
    "        if count2 == len_batch:\n",
    "            acc_avg_test = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            loss_avg_test = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            precision_avg_test = sum(batch_precision_test) / len(batch_precision_test)\n",
    "            recall_avg_test = sum(batch_recall_test) / len(batch_recall_test)\n",
    "            auc_avg_test = sum(batch_auc_test) / len(batch_auc_test)\n",
    "            f1_avg_test = sum(batch_f1_test) / len(batch_f1_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_precision_test = []\n",
    "            batch_recall_test = []\n",
    "            batch_auc_test = []\n",
    "            batch_f1_test = []\n",
    "            count2 = 0\n",
    "\n",
    "            print('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f} \\tPrecision: {:.3f} \\tRecall: {:.3f} \\tAUC: {:.3f} \\tF1-Score: {:.3f}'.format(\n",
    "                idx, acc_avg_test, loss_avg_test, precision_avg_test, recall_avg_test, auc_avg_test, f1_avg_test))\n",
    "\n",
    "            if l_epoch_check:\n",
    "                l_epoch_check = False\n",
    "\n",
    "                acc_avg_test_all = acc_avg_test\n",
    "                loss_avg_test_all = loss_avg_test\n",
    "\n",
    "                loss_test_collect_user.append(loss_avg_test_all)\n",
    "                acc_test_collect_user.append(acc_avg_test_all)\n",
    "\n",
    "            if fed_check:\n",
    "                fed_check = False\n",
    "                print(\"------------------------------------------------\")\n",
    "                print(\"------ Federation process at Server-Side ------- \")\n",
    "                print(\"------------------------------------------------\")\n",
    "\n",
    "                acc_avg_all_user = sum(acc_test_collect_user) / len(acc_test_collect_user)\n",
    "                loss_avg_all_user = sum(loss_test_collect_user) / len(loss_test_collect_user)\n",
    "\n",
    "                loss_test_collect.append(loss_avg_all_user)\n",
    "                acc_test_collect.append(acc_avg_all_user)\n",
    "                acc_test_collect_user = []\n",
    "                loss_test_collect_user = []\n",
    "\n",
    "                print(\"====================== SERVER V1==========================\")\n",
    "                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train, loss_avg_all_user_train))\n",
    "                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user, loss_avg_all_user))\n",
    "                print(\"==========================================================\")\n",
    "    return"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "82R9R7c6zK3x",
    "ExecuteTime": {
     "end_time": "2024-10-07T19:49:33.295508Z",
     "start_time": "2024-10-07T19:49:33.259740Z"
    }
   },
   "source": [
    "def evaluate_accuracy(net, loader, device, return_conf_matrix=False, num_classes=4):\n",
    "    net.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    \n",
    "    all_preds = torch.tensor(all_preds)\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "\n",
    "    \n",
    "    accuracy = torchmetrics.functional.accuracy(all_preds, all_labels, task='multiclass', num_classes=num_classes).item()\n",
    "    precision = torchmetrics.functional.precision(all_preds, all_labels, average='macro', task='multiclass', num_classes=num_classes).item()\n",
    "    recall = torchmetrics.functional.recall(all_preds, all_labels, average='macro', task='multiclass', num_classes=num_classes).item()\n",
    "    f1 = torchmetrics.functional.f1_score(all_preds, all_labels, average='macro', task='multiclass', num_classes=num_classes).item()\n",
    "    auc = torchmetrics.functional.auroc(F.softmax(outputs, dim=1), all_labels, task='multiclass', num_classes=num_classes).item()\n",
    "\n",
    "\n",
    "    conf_matrix = confusion_matrix(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n",
    "\n",
    "    if return_conf_matrix:\n",
    "        return accuracy, precision, recall, f1, auc, conf_matrix\n",
    "    else:\n",
    "        return accuracy, precision, recall, f1, auc\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "class Client(object):\n",
    "    def __init__(self, net_client_model, idx, lr, device, train_loader=None, test_loader=None, idxs=None, idxs_test=None):\n",
    "        self.idx = idx\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.local_ep = 1\n",
    "        self.ldr_train = train_loader\n",
    "        self.ldr_test = test_loader\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer_client, step_size=30, gamma=0.1)\n",
    "\n",
    "        for iter in range(self.local_ep):\n",
    "            len_batch = len(self.ldr_train)\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                fx = net(images)\n",
    "                client_fx = fx.clone().detach().requires_grad_(True)\n",
    "                dfx = train_server(client_fx, labels, iter, self.local_ep, self.idx, len_batch)\n",
    "                fx.backward(dfx)\n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)\n",
    "                optimizer_client.step()\n",
    "\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        return net.state_dict()\n",
    "\n",
    "    def evaluate(self, net, ell, num_classes=4):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            len_batch = len(self.ldr_test)\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                fx = net(images)\n",
    "                evaluate_server(fx, labels, self.idx, len_batch, ell, num_classes)\n",
    "\n",
    "        return\n",
    "\n",
    "def dataset_iid(dataset, num_users):\n",
    "    num_items = int(len(dataset) / num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Treino!\n"
   ],
   "metadata": {
    "id": "I50k6NHR8V9x"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T20:11:06.479394Z",
     "start_time": "2024-10-07T20:04:08.985995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epoch_times = []\n",
    "\n",
    "dict_users = dataset_iid(train_dataset, num_users)\n",
    "dict_users_test = dataset_iid(test_dataset, num_users)\n",
    "net_glob_client.train()\n",
    "\n",
    "w_glob_client = net_glob_client.state_dict()\n",
    "\n",
    "\n",
    "for iter in range(epochs):\n",
    "    start_time = time.time()\n",
    "    m = max(int(frac * num_users), 1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(\n",
    "            net_glob_client,\n",
    "            idx,\n",
    "            lr,\n",
    "            device,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            idxs=dict_users[idx],\n",
    "            idxs_test=dict_users_test[idx]\n",
    "        )\n",
    "\n",
    "        w_client = local.train(net=copy.deepcopy(net_glob_client).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "\n",
    "        local.evaluate(net=copy.deepcopy(net_glob_client).to(device), ell=iter)\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"------ FedServer: Federation process at Client-Side ------- \")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "\n",
    "    w_glob_client = FedAvg(w_locals_client)\n",
    "    net_glob_client.load_state_dict(w_glob_client)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    epoch_times.append(epoch_time)\n",
    "    print(f\"Epoch {iter + 1}/{epochs} - Time taken: {epoch_time:.2f} seconds\")\n",
    "\n",
    "print(\"Training and Evaluation completed!\")\n"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 28\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m idxs_users:\n\u001B[1;32m     17\u001B[0m     local \u001B[38;5;241m=\u001B[39m Client(\n\u001B[1;32m     18\u001B[0m         net_glob_client,\n\u001B[1;32m     19\u001B[0m         idx,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     25\u001B[0m         idxs_test\u001B[38;5;241m=\u001B[39mdict_users_test[idx]\n\u001B[1;32m     26\u001B[0m     )\n\u001B[0;32m---> 28\u001B[0m     w_client \u001B[38;5;241m=\u001B[39m \u001B[43mlocal\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet_glob_client\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     w_locals_client\u001B[38;5;241m.\u001B[39mappend(copy\u001B[38;5;241m.\u001B[39mdeepcopy(w_client))\n\u001B[1;32m     31\u001B[0m     local\u001B[38;5;241m.\u001B[39mevaluate(net\u001B[38;5;241m=\u001B[39mcopy\u001B[38;5;241m.\u001B[39mdeepcopy(net_glob_client)\u001B[38;5;241m.\u001B[39mto(device), ell\u001B[38;5;241m=\u001B[39m\u001B[38;5;28miter\u001B[39m)\n",
      "Cell \u001B[0;32mIn[12], line 69\u001B[0m, in \u001B[0;36mClient.train\u001B[0;34m(self, net)\u001B[0m\n\u001B[1;32m     67\u001B[0m fx \u001B[38;5;241m=\u001B[39m net(images)\n\u001B[1;32m     68\u001B[0m client_fx \u001B[38;5;241m=\u001B[39m fx\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 69\u001B[0m dfx \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient_fx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocal_ep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlen_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m fx\u001B[38;5;241m.\u001B[39mbackward(dfx)\n\u001B[1;32m     71\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(net\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m)\n",
      "Cell \u001B[0;32mIn[10], line 20\u001B[0m, in \u001B[0;36mtrain_server\u001B[0;34m(fx_client, y, l_epoch_count, l_epoch, idx, len_batch, num_classes)\u001B[0m\n\u001B[1;32m     17\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(fx_server, y)\n\u001B[1;32m     18\u001B[0m acc, precision, recall, f1, auc \u001B[38;5;241m=\u001B[39m calculate_metrics(fx_server, y, num_classes)\n\u001B[0;32m---> 20\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m dfx_client \u001B[38;5;241m=\u001B[39m fx_client\u001B[38;5;241m.\u001B[39mgrad\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m     22\u001B[0m optimizer_server\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:521\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    512\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    513\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    514\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    519\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    520\u001B[0m     )\n\u001B[0;32m--> 521\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:289\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    284\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 289\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:768\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    766\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    767\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 768\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    769\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    770\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    771\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    772\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "mount_file_id": "1Cjudpa5t47y1peQIuUWnPJ4F1B-C57Z5",
   "authorship_tag": "ABX9TyNfp+CtEj1OSf2X18Wu68ru",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
