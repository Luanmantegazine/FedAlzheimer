{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Luanmantegazine/TF/blob/main/FED_ADNIData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "seGN9Ju7v7w-",
    "ExecuteTime": {
     "end_time": "2024-08-03T20:31:43.498122Z",
     "start_time": "2024-08-03T20:31:41.107800Z"
    }
   },
   "source": [
    "import torch\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib as plt\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from imblearn.over_sampling import SMOTE\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datasets, transforms\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader, Dataset\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mF\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torchvision'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlknLHbixiCq"
   },
   "source": [
    "#Definindo o nÃºmero de clientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HtpTQpfMxhka",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b9877add-b320-4f89-e65b-53f73d5f1e20"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "num_users = 3\n",
    "num_classes =  4\n",
    "epochs = 100\n",
    "frac = 1\n",
    "lr= 0.0001\n",
    "batch_size = 128\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIgHK_5Cx0Xo"
   },
   "source": [
    "#Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TDdVPq2x4cf"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/FedAlzheimer/Data_ADNI'\n",
    "\n",
    "class NiftiDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root_dir, file) for file in os.listdir(root_dir) if file.endswith('.nii')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = nib.load(img_path).get_fdata()\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = torch.tensor(img, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = NiftiDataset(root_dir=os.path.join(data_path, 'train'), transform=train_transforms)\n",
    "test_dataset = NiftiDataset(root_dir=os.path.join(data_path, 'test'), transform=test_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzTpOB0SyjLK"
   },
   "source": [
    "#Definindo o treinamento do cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Xcv6TMcynpJ"
   },
   "outputs": [],
   "source": [
    "class ResNet50_client_side(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50_client_side, self).__init__()\n",
    "        self.layer1 = nn.Sequential (\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        )\n",
    "        self.layer2 = self._make_layer(64, 64, 3)\n",
    "\n",
    "    def _make_layer(self, in_planes, out_planes, blocks):\n",
    "        layers = []\n",
    "        layers.append(self._make_bottleneck(in_planes, out_planes, stride=1))\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(self._make_bottleneck(out_planes * 4, out_planes, stride=1))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_bottleneck(self, in_planes, planes, stride=1):\n",
    "        expansion = 4\n",
    "        out_planes = planes * expansion\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_planes, planes, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(planes),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(planes, out_planes, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual1 = self.layer1(x)\n",
    "        out1 = self.layer2(residual1)\n",
    "        out1 = F.relu(out1) if out1.size(1) == residual1.size(1) else nn.Conv2d(out1.size(1), residual1.size(1), kernel_size=1, bias=False).to(out1.device)(out1)\n",
    "        out1 += residual1\n",
    "        residual2 = F.relu(out1)\n",
    "        return residual2\n",
    "\n",
    "net_glob_client = ResNet50_client_side()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net_glob_client = nn.DataParallel(net_glob_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPhaspYryuye"
   },
   "source": [
    "#Definindo o treinamento do servidor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LapoJhY6yq28"
   },
   "outputs": [],
   "source": [
    "class Baseblock(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, input_planes, planes, stride=1, dim_change=None):\n",
    "        super(Baseblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_planes, planes, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dim_change = dim_change\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "\n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = F.relu(self.bn2(self.conv2(output)))\n",
    "        output = self.bn3(self.conv3(output))\n",
    "\n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "\n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class ResNet50_server_side(nn.Module):\n",
    "    def __init__(self, block, num_layers, num_classes=4):\n",
    "        super(ResNet50_server_side, self).__init__()\n",
    "        self.input_planes = 64\n",
    "        self.conv1 = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, num_layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        dim_change = None\n",
    "        if stride != 1 or self.input_planes != planes * block.expansion:\n",
    "            dim_change = nn.Sequential(\n",
    "                nn.Conv2d(self.input_planes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.input_planes, planes, stride, dim_change))\n",
    "        self.input_planes = planes * block.expansion\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.input_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net_glob_server = ResNet50_server_side(Baseblock, [3, 4, 6, 3], num_classes=4)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"We use\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net_glob_server = nn.DataParallel(net_glob_server)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiPpKWagy5OH"
   },
   "outputs": [],
   "source": [
    "loss_train_collect = []\n",
    "acc_train_collect = []\n",
    "loss_test_collect = []\n",
    "acc_test_collect = []\n",
    "auc_train_collect = []\n",
    "auc_test_collect = []\n",
    "batch_acc_train = []\n",
    "batch_loss_train = []\n",
    "batch_precision_train = []\n",
    "batch_recall_train = []\n",
    "acc_train_collect_user = []\n",
    "loss_train_collect_user = []\n",
    "loss_test_collect_user = []\n",
    "batch_auc_train = []\n",
    "batch_acc_test = []\n",
    "batch_loss_test = []\n",
    "batch_prec_test = []\n",
    "batch_recall_test = []\n",
    "\n",
    "count1 = 0\n",
    "count2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r48wsNx9y7VM"
   },
   "outputs": [],
   "source": [
    "def FedAvg(w):\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for k in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[k] += w[i][k]\n",
    "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
    "    return w_avg\n",
    "\n",
    "def calculate_metrics(fx, y, num_classes):\n",
    "    preds = fx.argmax(dim=1)\n",
    "    accuracy = torchmetrics.functional.accuracy(preds, y, task='multiclass', num_classes=num_classes)\n",
    "    precision = torchmetrics.functional.precision(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
    "    recall = torchmetrics.functional.recall(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
    "    f1 = torchmetrics.functional.f1_score(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
    "    auc = torchmetrics.functional.auroc(F.softmax(fx, dim=1), y, task='multiclass', num_classes=num_classes)\n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "w_glob_server = net_glob_server.state_dict()\n",
    "w_locals_server = []\n",
    "\n",
    "idx_collect = []\n",
    "l_epoch_check = False\n",
    "fed_check = False\n",
    "\n",
    "net_model_server = [ResNet50_server_side(Baseblock, [3, 4, 6, 3], num_classes) for i in range(num_users)]\n",
    "\n",
    "net_server = copy.deepcopy(net_model_server[0]).to(device)\n",
    "optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybaVUIqZy-1j"
   },
   "outputs": [],
   "source": [
    "def train_server(fx_client, y, l_epoch_count, l_epoch, idx, len_batch, num_classes=4):\n",
    "    global net_model_server, criterion, optimizer_server, device\n",
    "    global batch_acc_train, batch_loss_train, batch_precision_train, batch_recall_train, batch_auc_train\n",
    "    global l_epoch_check, fed_check, loss_train_collect, acc_train_collect, count1\n",
    "    global acc_avg_all_user_train, loss_avg_all_user_train, idx_collect, w_locals_server, w_glob_server, net_server\n",
    "    global loss_train_collect_user, acc_train_collect_user, lr\n",
    "\n",
    "    net_server = net_model_server[idx].to(device)\n",
    "    net_server.train()\n",
    "    optimizer_server = torch.optim.Adam(net_server.parameters(), lr=lr)\n",
    "\n",
    "    optimizer_server.zero_grad()\n",
    "    fx_client = fx_client.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    fx_server = net_server(fx_client)\n",
    "    loss = criterion(fx_server, y)\n",
    "    acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes)\n",
    "\n",
    "    loss.backward()\n",
    "    dfx_client = fx_client.grad.clone().detach()\n",
    "    optimizer_server.step()\n",
    "\n",
    "    batch_loss_train.append(loss.item())\n",
    "    batch_acc_train.append(acc.item())\n",
    "    batch_precision_train.append(precision.item())\n",
    "    batch_recall_train.append(recall.item())\n",
    "    batch_auc_train.append(auc.item())\n",
    "\n",
    "    net_model_server[idx] = net_server\n",
    "\n",
    "    count1 += 1\n",
    "    if count1 == len_batch:\n",
    "        acc_avg_train = sum(batch_acc_train) / len(batch_acc_train)\n",
    "        loss_avg_train = sum(batch_loss_train) / len(batch_loss_train)\n",
    "        precision_avg_train = sum(batch_precision_train) / len(batch_precision_train)\n",
    "        recall_avg_train = sum(batch_recall_train) / len(batch_recall_train)\n",
    "        auc_avg_train = sum(batch_auc_train) / len(batch_auc_train)\n",
    "\n",
    "        batch_acc_train.clear()\n",
    "        batch_loss_train.clear()\n",
    "        batch_precision_train.clear()\n",
    "        batch_recall_train.clear()\n",
    "        batch_auc_train.clear()\n",
    "        count1 = 0\n",
    "\n",
    "        print(f'Client{idx} Train => Local Epoch: {l_epoch_count} \\tAcc: {acc_avg_train:.3f} \\tLoss: {loss_avg_train:.4f} \\tPrecision: {precision_avg_train:.3f} \\tRecall: {recall_avg_train:.3f} \\tAUC: {auc_avg_train:.3f}')\n",
    "\n",
    "        w_server = net_server.state_dict()\n",
    "\n",
    "        if l_epoch_count == l_epoch - 1:\n",
    "            l_epoch_check = True\n",
    "            w_locals_server.append(copy.deepcopy(w_server))\n",
    "\n",
    "            acc_avg_train_all = acc_avg_train\n",
    "            loss_avg_train_all = loss_avg_train\n",
    "\n",
    "            loss_train_collect_user.append(loss_avg_train_all)\n",
    "            acc_train_collect_user.append(acc_avg_train_all)\n",
    "\n",
    "            if idx not in idx_collect:\n",
    "                idx_collect.append(idx)\n",
    "\n",
    "        if len(idx_collect) == num_users:\n",
    "            fed_check = True\n",
    "            w_glob_server = FedAvg(w_locals_server)\n",
    "            net_glob_server.load_state_dict(w_glob_server)\n",
    "            net_model_server = [copy.deepcopy(net_glob_server) for _ in range(num_users)]\n",
    "            w_locals_server.clear()\n",
    "            idx_collect.clear()\n",
    "\n",
    "            acc_avg_all_user_train = sum(acc_train_collect_user) / len(acc_train_collect_user)\n",
    "            loss_avg_all_user_train = sum(loss_train_collect_user) / len(loss_train_collect_user)\n",
    "\n",
    "            loss_train_collect.append(loss_avg_all_user_train)\n",
    "            acc_train_collect.append(acc_avg_all_user_train)\n",
    "\n",
    "            acc_train_collect_user.clear()\n",
    "            loss_train_collect_user.clear()\n",
    "\n",
    "    return dfx_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-azC4sjfzBte"
   },
   "outputs": [],
   "source": [
    "def evaluate_server(fx_client, y, idx, len_batch, ell, num_classes=4):\n",
    "    global net_model_server, criterion, batch_acc_test, batch_loss_test, check_fed, net_server, net_glob_server\n",
    "    global loss_test_collect, acc_test_collect, count2, num_users, acc_avg_train_all, loss_avg_train_all, w_glob_server, l_epoch_check, fed_check\n",
    "    global loss_test_collect_user, acc_test_collect_user, acc_avg_all_user_train, loss_avg_all_user_train\n",
    "\n",
    "    batch_precision_test = []\n",
    "    acc_test_collect_user = []\n",
    "    batch_recall_test = []\n",
    "    batch_auc_test = []\n",
    "    batch_f1_test = []\n",
    "\n",
    "    net = copy.deepcopy(net_model_server[idx]).to(device)\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fx_client = fx_client.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        fx_server = net(fx_client)\n",
    "        loss = criterion(fx_server, y)\n",
    "\n",
    "        acc, precision, recall, f1, auc = calculate_metrics(fx_server, y, num_classes)\n",
    "\n",
    "        batch_loss_test.append(loss.item())\n",
    "        batch_acc_test.append(acc.item())\n",
    "        batch_precision_test.append(precision.item())\n",
    "        batch_recall_test.append(recall.item())\n",
    "        batch_auc_test.append(auc.item())\n",
    "        batch_f1_test.append(f1.item())\n",
    "\n",
    "        count2 += 1\n",
    "        if count2 == len_batch:\n",
    "            acc_avg_test = sum(batch_acc_test) / len(batch_acc_test)\n",
    "            loss_avg_test = sum(batch_loss_test) / len(batch_loss_test)\n",
    "            precision_avg_test = sum(batch_precision_test) / len(batch_precision_test)\n",
    "            recall_avg_test = sum(batch_recall_test) / len(batch_recall_test)\n",
    "            auc_avg_test = sum(batch_auc_test) / len(batch_auc_test)\n",
    "            f1_avg_test = sum(batch_f1_test) / len(batch_f1_test)\n",
    "\n",
    "            batch_acc_test = []\n",
    "            batch_loss_test = []\n",
    "            batch_precision_test = []\n",
    "            batch_recall_test = []\n",
    "            batch_auc_test = []\n",
    "            batch_f1_test = []\n",
    "            count2 = 0\n",
    "\n",
    "            print('Client{} Test =>                   \\tAcc: {:.3f} \\tLoss: {:.4f} \\tPrecision: {:.3f} \\tRecall: {:.3f} \\tAUC: {:.3f} \\tF1-Score: {:.3f}'.format(\n",
    "                idx, acc_avg_test, loss_avg_test, precision_avg_test, recall_avg_test, auc_avg_test, f1_avg_test))\n",
    "\n",
    "            if l_epoch_check:\n",
    "                l_epoch_check = False\n",
    "\n",
    "                acc_avg_test_all = acc_avg_test\n",
    "                loss_avg_test_all = loss_avg_test\n",
    "\n",
    "                loss_test_collect_user.append(loss_avg_test_all)\n",
    "                acc_test_collect_user.append(acc_avg_test_all)\n",
    "\n",
    "            if fed_check:\n",
    "                fed_check = False\n",
    "                print(\"------------------------------------------------\")\n",
    "                print(\"------ Federation process at Server-Side ------- \")\n",
    "                print(\"------------------------------------------------\")\n",
    "\n",
    "                acc_avg_all_user = sum(acc_test_collect_user) / len(acc_test_collect_user)\n",
    "                loss_avg_all_user = sum(loss_test_collect_user) / len(loss_test_collect_user)\n",
    "\n",
    "                loss_test_collect.append(loss_avg_all_user)\n",
    "                acc_test_collect.append(acc_avg_all_user)\n",
    "                acc_test_collect_user = []\n",
    "                loss_test_collect_user = []\n",
    "\n",
    "                print(\"====================== SERVER V1==========================\")\n",
    "                print(' Train: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user_train, loss_avg_all_user_train))\n",
    "                print(' Test: Round {:3d}, Avg Accuracy {:.3f} | Avg Loss {:.3f}'.format(ell, acc_avg_all_user, loss_avg_all_user))\n",
    "                print(\"==========================================================\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82R9R7c6zK3x"
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, loader, device, return_conf_matrix=False, num_classes=4):\n",
    "    net.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    accuracy = torchmetrics.functional.accuracy(preds, y, task='multiclass', num_classes=num_classes)\n",
    "    precision = torchmetrics.functional.precision(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
    "    recall = torchmetrics.functional.recall(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
    "    f1 = torchmetrics.functional.f1_score(preds, y, average='macro', task='multiclass', num_classes=num_classes)\n",
    "    auc = torchmetrics.functional.auroc(F.softmax(fx, dim=1), y, task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "            accuracy.update(predicted, labels)\n",
    "            precision.update(predicted, labels)\n",
    "            recall.update(predicted, labels)\n",
    "            f1.update(predicted, labels)\n",
    "            auc.update(outputs, labels)\n",
    "\n",
    "    accuracy_value = accuracy.compute().item()\n",
    "    precision_value = precision.compute().item()\n",
    "    recall_value = recall.compute().item()\n",
    "    f1_value = f1.compute().item()\n",
    "    auc_value = auc.compute().item()\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    if return_conf_matrix:\n",
    "        return accuracy_value, precision_value, recall_value, f1_value, auc_value, conf_matrix\n",
    "    else:\n",
    "        return accuracy_value, precision_value, recall_value, f1_value, auc_value\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "class Client(object):\n",
    "    def __init__(self, net_client_model, idx, lr, device, train_loader=None, test_loader=None, idxs=None, idxs_test=None):\n",
    "        self.idx = idx\n",
    "        self.device = device\n",
    "        self.lr = lr\n",
    "        self.local_ep = 1\n",
    "        self.ldr_train = train_loader\n",
    "        self.ldr_test = test_loader\n",
    "\n",
    "    def train(self, net):\n",
    "        net.train()\n",
    "        optimizer_client = torch.optim.Adam(net.parameters(), lr=self.lr)\n",
    "        scheduler = StepLR(optimizer_client, step_size=30, gamma=0.1)\n",
    "\n",
    "        for iter in range(self.local_ep):\n",
    "            len_batch = len(self.ldr_train)\n",
    "\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                optimizer_client.zero_grad()\n",
    "                fx = net(images)\n",
    "                client_fx = fx.clone().detach().requires_grad_(True)\n",
    "                dfx = train_server(client_fx, labels, iter, self.local_ep, self.idx, len_batch)\n",
    "                fx.backward(dfx)\n",
    "                optimizer_client.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        return net.state_dict()\n",
    "\n",
    "\n",
    "    def evaluate(self, net, ell, num_classes=4):\n",
    "        net.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            len_batch = len(self.ldr_test)\n",
    "            for batch_idx, (images, labels) in enumerate(self.ldr_test):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                fx = net(images)\n",
    "                evaluate_server(fx, labels, self.idx, len_batch, ell, num_classes)\n",
    "\n",
    "        return\n",
    "\n",
    "def dataset_iid(dataset, num_users):\n",
    "\n",
    "    num_items = int(len(dataset) / num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Treino!\n"
   ],
   "metadata": {
    "id": "I50k6NHR8V9x"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZyuk01ozOIl",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "outputId": "8e927112-7041-4f00-e6a0-f91269b59b72"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Input image tensor permitted channel values are [1, 3], but found 256",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-18-c6d5ea333054>\u001B[0m in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     26\u001B[0m         )\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m         \u001B[0mw_client\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlocal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnet_glob_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0mw_locals_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdeepcopy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mw_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-15-9bb089e9ce89>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, net)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0mlen_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mldr_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 70\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0mbatch_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mldr_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     71\u001B[0m                 \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m                 \u001B[0moptimizer_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    629\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 631\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    632\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    674\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 675\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    676\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    677\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     49\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitems__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     49\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitems__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-7-8af66b8282fc>\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     93\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     94\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 95\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     96\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1531\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1532\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1533\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1534\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1539\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1540\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1542\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1543\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m   1276\u001B[0m                 \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madjust_contrast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcontrast_factor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1277\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mfn_id\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0msaturation_factor\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1278\u001B[0;31m                 \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madjust_saturation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msaturation_factor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1279\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mfn_id\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m3\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mhue_factor\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1280\u001B[0m                 \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madjust_hue\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhue_factor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36madjust_saturation\u001B[0;34m(img, saturation_factor)\u001B[0m\n\u001B[1;32m    920\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mF_pil\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madjust_saturation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msaturation_factor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 922\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mF_t\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madjust_saturation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msaturation_factor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    923\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    924\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001B[0m in \u001B[0;36madjust_saturation\u001B[0;34m(img, saturation_factor)\u001B[0m\n\u001B[1;32m    226\u001B[0m     \u001B[0m_assert_image_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 228\u001B[0;31m     \u001B[0m_assert_channels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    229\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    230\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mget_dimensions\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Match PIL behaviour\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001B[0m in \u001B[0;36m_assert_channels\u001B[0;34m(img, permitted)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0mc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_dimensions\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpermitted\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Input image tensor permitted channel values are {permitted}, but found {c}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Input image tensor permitted channel values are [1, 3], but found 256"
     ]
    }
   ],
   "source": [
    "epoch_times = []\n",
    "\n",
    "dict_users = dataset_iid(train_dataset, num_users)\n",
    "dict_users_test = dataset_iid(test_dataset, num_users)\n",
    "net_glob_client.train()\n",
    "\n",
    "w_glob_client = net_glob_client.state_dict()\n",
    "\n",
    "\n",
    "for iter in range(epochs):\n",
    "    start_time = time.time()\n",
    "    m = max(int(frac * num_users), 1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False)\n",
    "    w_locals_client = []\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local = Client(\n",
    "            net_glob_client,\n",
    "            idx,\n",
    "            lr,\n",
    "            device,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            idxs=dict_users[idx],\n",
    "            idxs_test=dict_users_test[idx]\n",
    "        )\n",
    "\n",
    "        w_client = local.train(net=copy.deepcopy(net_glob_client).to(device))\n",
    "        w_locals_client.append(copy.deepcopy(w_client))\n",
    "\n",
    "        local.evaluate(net=copy.deepcopy(net_glob_client).to(device), ell=iter)\n",
    "\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    print(\"------ FedServer: Federation process at Client-Side ------- \")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "\n",
    "    w_glob_client = FedAvg(w_locals_client)\n",
    "    net_glob_client.load_state_dict(w_glob_client)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    epoch_times.append(epoch_time)\n",
    "    print(f\"Epoch {iter + 1}/{epochs} - Time taken: {epoch_time:.2f} seconds\")\n",
    "\n",
    "print(\"Training and Evaluation completed!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "mount_file_id": "1Cjudpa5t47y1peQIuUWnPJ4F1B-C57Z5",
   "authorship_tag": "ABX9TyNfp+CtEj1OSf2X18Wu68ru",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
