{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luanmantegazine/FedAlzheimer/blob/main/FlowerFL_(FedAvgM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d3Exonuq6qst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c37992e-607b-47b5-ed58-1ee41c11c53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.11/dist-packages (1.20.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.74.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.62.3 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.62.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Requirement already satisfied: ray==2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.31.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.11/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (3.18.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (4.25.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (25.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray==2.31.0->flwr[simulation]) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (4.14.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.22)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.26.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.15.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \"flwr[simulation]\"\n",
        "!pip install torch torchvision scikit-learn matplotlib torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rKZf3N4n4rjm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "from collections import Counter, OrderedDict\n",
        "from contextlib import nullcontext\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.client import ClientApp\n",
        "from flwr.server import ServerApp, ServerAppComponents, ServerConfig\n",
        "from flwr.common import NDArrays, ndarrays_to_parameters, Context\n",
        "from flwr.server.strategy import FedAvgM\n",
        "from flwr.simulation import run_simulation\n",
        "\n",
        "import torchmetrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "os.environ.pop(\"NVIDIA_VISIBLE_DEVICES\", None)\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
      ],
      "metadata": {
        "id": "B-hDgoe2YYW3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPeZNGj_7hcm"
      },
      "source": [
        "Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cQI1XkY-7l0Q"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "\n",
        "  data_path: str = \"/content/drive/MyDrive/TCC - Grupo SLD/Projeto 2/ADNI\"\n",
        "\n",
        "  num_clients = 3\n",
        "  num_rounds = 10\n",
        "  seed = 1234\n",
        "\n",
        "  partition_strategy = \"dirichlet\"\n",
        "  dirichlet_alpha = 0.5\n",
        "  shards_per_clients = 2\n",
        "\n",
        "  batch_size = 32\n",
        "  local_epochs = 1\n",
        "  learning_rate = 1e-4\n",
        "\n",
        "  server_learning_rate = 0.001\n",
        "  server_momentum = 0.9\n",
        "\n",
        "config = Config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v6aTIYn-_KCg"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_device() -> torch.device:\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "def build_transforms():\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),\n",
        "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    return train_transform, test_transform\n",
        "\n",
        "def partition_iid(indices: np.ndarray, num_clients: int):\n",
        "    splits = np.array_split(indices, num_clients)\n",
        "    return {cid: split for cid, split in enumerate(splits)}\n",
        "\n",
        "def partition_dirichlet(labels_all: List[int], idxs: np.ndarray, num_clients: int, alpha: float, seed: int, min_size: int = 10):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    labels = np.array([labels_all[i] for i in idxs])\n",
        "    client_indices = {i: [] for i in range(num_clients)}\n",
        "    min_client_size = 0\n",
        "    while min_client_size < min_size:\n",
        "        client_indices = {i: [] for i in range(num_clients)}\n",
        "        for c in np.unique(labels):\n",
        "            idx_c = idxs[labels == c]\n",
        "            rng.shuffle(idx_c)\n",
        "            proportions = rng.dirichlet(alpha=np.repeat(alpha, num_clients))\n",
        "            proportions /= proportions.sum()\n",
        "            splits = (np.cumsum(proportions) * len(idx_c)).astype(int)[:-1]\n",
        "            chunks = np.split(idx_c, splits)\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                client_indices[i].extend(chunk.tolist())\n",
        "        sizes = [len(client_indices[i]) for i in range(num_clients)]\n",
        "        if not sizes or min(sizes) == 0:\n",
        "            min_client_size = 0\n",
        "            continue\n",
        "        min_client_size = min(sizes)\n",
        "    return {i: np.array(v) for i, v in client_indices.items()}\n",
        "\n",
        "def partition_shards(labels_all: List[int], idxs: np.ndarray, num_clients: int, shards_per_client: int, seed: int):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    labels = np.array([labels_all[i] for i in idxs])\n",
        "    sorted_order = np.argsort(labels)\n",
        "    sorted_idxs = idxs[sorted_order]\n",
        "    num_shards = num_clients * shards_per_client\n",
        "    shard_size = int(np.ceil(len(sorted_idxs) / num_shards))\n",
        "    shards = [sorted_idxs[i * shard_size:(i + 1) * shard_size] for i in range(num_shards)]\n",
        "    rng.shuffle(shards)\n",
        "    client_indices = {i: np.concatenate(shards[i * shards_per_client:(i + 1) * shards_per_client]) for i in range(num_clients)}\n",
        "    return client_indices\n",
        "\n",
        "def make_weights_for_balanced_classes(indices: List[int], imagefolder: datasets.ImageFolder, num_classes: int):\n",
        "    labels = [imagefolder.samples[i][1] for i in indices]\n",
        "    cnt = Counter(labels)\n",
        "    class_weight = {c: len(labels) / (num_classes * cnt[c]) if cnt[c] > 0 else 0 for c in range(num_classes)}\n",
        "    sample_weights = [class_weight[lbl] for lbl in labels]\n",
        "    return torch.DoubleTensor(sample_weights)\n",
        "\n",
        "def build_model(num_classes: int):\n",
        "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(nn.Dropout(p=0.3), nn.Linear(in_features, num_classes))\n",
        "    return model\n",
        "\n",
        "def get_params(model: nn.Module):\n",
        "    return [v.detach().cpu().numpy() for _, v in model.state_dict().items()]\n",
        "\n",
        "def set_params(model: nn.Module, params: NDArrays):\n",
        "    state_dict = model.state_dict()\n",
        "    new_state_dict = OrderedDict({k: torch.tensor(v) for k, v in zip(state_dict.keys(), params)})\n",
        "    model.load_state_dict(new_state_dict, strict=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "sOeCv7_r_MR2"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Metrics:\n",
        "    loss: float\n",
        "    accuracy: float\n",
        "    precision: float\n",
        "    recall: float\n",
        "    f1: float\n",
        "    auc: float\n",
        "\n",
        "def evaluate_model(model: nn.Module, loader: DataLoader, device: torch.device, num_classes: int) -> Metrics:\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses, all_logits, all_labels = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            losses.append(criterion(logits, y).item())\n",
        "            all_logits.append(logits.cpu())\n",
        "            all_labels.append(y.cpu())\n",
        "    logits = torch.cat(all_logits)\n",
        "    labels = torch.cat(all_labels)\n",
        "    preds = logits.argmax(dim=1)\n",
        "    prob = F.softmax(logits, dim=1)\n",
        "\n",
        "    try:\n",
        "        auc_score = torchmetrics.functional.auroc(prob, labels, task=\"multiclass\", num_classes=num_classes).item()\n",
        "    except ValueError:\n",
        "        auc_score = 0.0\n",
        "\n",
        "    return Metrics(\n",
        "        loss=float(np.mean(losses)),\n",
        "        accuracy=torchmetrics.functional.accuracy(preds, labels, task=\"multiclass\", num_classes=num_classes).item(),\n",
        "        precision=torchmetrics.functional.precision(preds, labels, average=\"macro\", task=\"multiclass\", num_classes=num_classes, zero_division=0).item(),\n",
        "        recall=torchmetrics.functional.recall(preds, labels, average=\"macro\", task=\"multiclass\", num_classes=num_classes, zero_division=0).item(),\n",
        "        f1=torchmetrics.functional.f1_score(preds, labels, average=\"macro\", task=\"multiclass\", num_classes=num_classes, zero_division=0).item(),\n",
        "        auc=auc_score,\n",
        "    )\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Dict[str, float]]]):\n",
        "  total_examples = sum(n for n, _ in metrics)\n",
        "  if total_examples == 0: return {}\n",
        "  metric_keys = metrics[0][1].keys()\n",
        "  return {k: sum(n * m.get(k, 0.0) for n, m in metrics) / total_examples for k in metric_keys}\n",
        "\n",
        "\n",
        "class TransformingSubset(Dataset):\n",
        "    def __init__(self, subset, transform):\n",
        "        self.subset, self.transform = subset, transform\n",
        "    def __len__(self): return len(self.subset)\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.subset[idx]\n",
        "        if self.transform: x = self.transform(x)\n",
        "        return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AKu6ib4u_QQE"
      },
      "outputs": [],
      "source": [
        "class AlzheimerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, full_dataset, train_idx, test_idx, num_classes, lr, batch_size, local_epochs, device):\n",
        "        self.cid = cid\n",
        "        self.num_classes = num_classes\n",
        "        self.device = device\n",
        "        self.model = build_model(num_classes).to(device)\n",
        "        self.lr = lr\n",
        "        self.local_epochs = local_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.use_cuda = False\n",
        "\n",
        "        train_tf, test_tf = build_transforms()\n",
        "        sub_train = TransformingSubset(Subset(full_dataset, train_idx), train_tf)\n",
        "        sub_test  = TransformingSubset(Subset(full_dataset, test_idx),  test_tf)\n",
        "\n",
        "        sampler = None\n",
        "        if isinstance(full_dataset, datasets.ImageFolder) and len(train_idx) > 0:\n",
        "            weights = make_weights_for_balanced_classes(train_idx, full_dataset, num_classes)\n",
        "            sampler = WeightedRandomSampler(weights, num_samples=len(train_idx), replacement=True)\n",
        "\n",
        "        self.train_loader = DataLoader(sub_train, batch_size=batch_size, shuffle=(sampler is None),\n",
        "                                       sampler=sampler, num_workers=0, persistent_workers=False, pin_memory=False)\n",
        "        self.test_loader  = DataLoader(sub_test,  batch_size=batch_size, shuffle=False, num_workers=0,\n",
        "                                       persistent_workers=False, pin_memory=False)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.05).to(device)\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "        self.model = build_model(num_classes).to(self.device)\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=False)\n",
        "\n",
        "    def get_parameters(self, config=None):\n",
        "        return get_params(self.model)\n",
        "\n",
        "    def fit(self, parameters, config_fit):\n",
        "        set_params(self.model, parameters)\n",
        "        epochs = int(config_fit.get(\"local_epochs\", self.local_epochs)) if config_fit else self.local_epochs\n",
        "        self.model.train()\n",
        "\n",
        "        amp_ctx = nullcontext()\n",
        "\n",
        "        for _ in range(epochs):\n",
        "          for x, y in self.train_loader:\n",
        "              x, y = x.to(self.device), y.to(self.device)\n",
        "              self.optimizer.zero_grad(set_to_none=True)\n",
        "              with amp_ctx:\n",
        "                  loss = self.criterion(self.model(x), y)\n",
        "              loss.backward()\n",
        "              self.optimizer.step()\n",
        "\n",
        "        m = evaluate_model(self.model, self.test_loader, self.device, self.num_classes)\n",
        "        return get_params(self.model), len(self.train_loader.dataset), {\n",
        "            \"accuracy_local\": m.accuracy, \"f1_local\": m.f1\n",
        "        }\n",
        "    def evaluate(self, parameters, config_eval):\n",
        "        set_params(self.model, parameters)\n",
        "        m = evaluate_model(self.model, self.test_loader, self.device, self.num_classes)\n",
        "        return m.loss, len(self.test_loader.dataset), {\"accuracy\": m.accuracy, \"f1\": m.f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLm3h_FC_Q81",
        "outputId": "1fb3a9e3-3462-473f-fc6e-96943703a2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cpu\n",
            "Dataset carregado com sucesso. Encontradas 545 imagens em 3 classes.\n",
            "Classes: ['AD', 'CN', 'MCI']\n"
          ]
        }
      ],
      "source": [
        "seed_everything(config.seed)\n",
        "device = get_device()\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "\n",
        "full_dataset = datasets.ImageFolder(root=config.data_path)\n",
        "labels_all = [lbl for _, lbl in full_dataset.samples]\n",
        "num_classes = len(full_dataset.classes)\n",
        "class_names = full_dataset.classes\n",
        "print(f\"Dataset carregado com sucesso. Encontradas {len(labels_all)} imagens em {num_classes} classes.\")\n",
        "print(f\"Classes: {class_names}\")\n",
        "\n",
        "idx_train, idx_test = train_test_split(\n",
        "    np.arange(len(full_dataset)),\n",
        "    test_size=0.2,\n",
        "    stratify=labels_all,\n",
        "    random_state=config.seed\n",
        ")\n",
        "\n",
        "def make_partitions():\n",
        "  if config.partition_strategy == \"iid\":\n",
        "    parts_train = partition_iid(idx_train, config.num_clients)\n",
        "  if config.partition_strategy == \"dirichlet\":\n",
        "    parts_train = partition_dirichlet(labels_all, idx_train, config.num_clients, config.dirichlet_alpha, config.seed)\n",
        "  return partition_dirichlet(labels_all, idx_train, config.num_clients, config.dirichlet_alpha, config.seed)\n",
        "\n",
        "parts_train = make_partitions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cseXbgjA_Yv-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "outputId": "a4672ffe-a31e-4d24-f42e-96b4fddfa8f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_data_distribution(partitions: Dict[int, np.ndarray], all_labels: List[int], class_names: List[str]):\n",
        "\n",
        "    num_clients = len(partitions)\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "    client_distributions = []\n",
        "    for cid in range(num_clients):\n",
        "        client_labels = [all_labels[i] for i in partitions[cid]]\n",
        "        class_counts = Counter(client_labels)\n",
        "        client_distributions.append([class_counts.get(i, 0) for i in range(len(class_names))])\n",
        "\n",
        "    client_distributions = np.array(client_distributions)\n",
        "    bottom = np.zeros(num_clients)\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        ax.bar(range(num_clients), client_distributions[:, i], bottom=bottom, label=class_name)\n",
        "        bottom += client_distributions[:, i]\n",
        "\n",
        "    ax.set_title(f\"Distribuição de Dados por Cliente (Estratégia: {config.partition_strategy})\")\n",
        "    ax.set_xlabel(\"ID do Cliente\")\n",
        "    ax.set_ylabel(\"Número de Amostras\")\n",
        "    ax.set_xticks(range(num_clients))\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "if 'parts_train' in locals() and parts_train is not None:\n",
        "    plot_data_distribution(parts_train, labels_all, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8qmuwYr_d3m",
        "outputId": "9b5f858b-fc43-40ab-f0ad-402816c7785c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apps prontos. Iniciando simulação...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py:344: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  img = Image.fromarray(np_img, \"RGB\")\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 1.1330315470695496, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.45584750175476074}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(pid=8092)\u001b[0m 2025-08-12 17:54:08.933435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=8092)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=8092)\u001b[0m E0000 00:00:1755021248.969131    8092 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=8092)\u001b[0m E0000 00:00:1755021248.979384    8092 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=8091)\u001b[0m W0000 00:00:1755021248.975902    8091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8091)\u001b[0m W0000 00:00:1755021248.975932    8091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8091)\u001b[0m W0000 00:00:1755021248.975936    8091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=8091)\u001b[0m W0000 00:00:1755021248.975941    8091 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(pid=8091)\u001b[0m 2025-08-12 17:54:08.905205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=8091)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=8091)\u001b[0m E0000 00:00:1755021248.939314    8091 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=8091)\u001b[0m E0000 00:00:1755021248.949813    8091 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=8092)\u001b[0m W0000 00:00:1755021249.005482    8092 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/transforms/_functional_pil.py:344: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m   img = Image.fromarray(np_img, \"RGB\")\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:324: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m   return Image.fromarray(npimg, mode=mode)\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /usr/local/lib/python3.11/dist-packages/torchvision/transforms/functional.py:324: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m   img = Image.fromarray(np_img, \"RGB\")\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m   return Image.fromarray(npimg, mode=mode)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 1.1330666244029999, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.45553338527679443}, 133.30592009399993)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 1.133132427930832, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.45548149943351746}, 254.162045949)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 1.1332235038280487, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.45529425144195557}, 368.333575957)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.1333390772342682, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.45518192648887634}, 479.09427325799993)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.1334699988365173, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.4550696313381195}, 586.224730527)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (6, 1.1336226165294647, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.4552942216396332}, 694.5666742740002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (7, 1.1337853074073792, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.4556083679199219}, 802.1107121490002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (8, 1.133967012166977, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.45549604296684265}, 911.8717021280002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (9, 1.1341663300991058, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.4554586708545685}, 1020.9271746440002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (10, 1.134373277425766, {'accuracy': 0.4678899049758911, 'precision': 0.2420634925365448, 'recall': 0.3237246572971344, 'f1': 0.2276371270418167, 'auc': 0.4552195370197296}, 1129.7769208490001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8091)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[36m(ClientAppActor pid=8092)\u001b[0m /tmp/ipython-input-3968308317.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 1148.00s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.1330666244029999\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.133132427930832\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.1332235038280487\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.1333390772342682\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.1334699988365173\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 1.1336226165294647\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 1.1337853074073792\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 1.133967012166977\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 1.1341663300991058\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 1.134373277425766\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 1.1330315470695496\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.1330666244029999\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 1.133132427930832\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.1332235038280487\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 1.1333390772342682\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 1.1334699988365173\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 1.1336226165294647\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 1.1337853074073792\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 1.133967012166977\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 1.1341663300991058\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 1.134373277425766\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (6, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (7, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (8, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (9, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (10, 0.4678899049758911)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'f1': [(1, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (2, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (3, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (4, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (5, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (6, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (7, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (8, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (9, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (10, 0.2276371270418167)]}\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (1, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (6, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (7, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (8, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (9, 0.4678899049758911),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (10, 0.4678899049758911)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'auc': [(0, 0.45584750175476074),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (1, 0.45553338527679443),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (2, 0.45548149943351746),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (3, 0.45529425144195557),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (4, 0.45518192648887634),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (5, 0.4550696313381195),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (6, 0.4552942216396332),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (7, 0.4556083679199219),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (8, 0.45549604296684265),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (9, 0.4554586708545685),\n",
            "\u001b[92mINFO \u001b[0m:      \t         (10, 0.4552195370197296)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'f1': [(0, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (1, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (2, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (3, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (4, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (5, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (6, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (7, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (8, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (9, 0.2276371270418167),\n",
            "\u001b[92mINFO \u001b[0m:      \t        (10, 0.2276371270418167)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'precision': [(0, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (1, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (2, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (3, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (4, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (5, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (6, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (7, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (8, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (9, 0.2420634925365448),\n",
            "\u001b[92mINFO \u001b[0m:      \t               (10, 0.2420634925365448)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'recall': [(0, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (1, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (2, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (3, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (4, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (5, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (6, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (7, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (8, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (9, 0.3237246572971344),\n",
            "\u001b[92mINFO \u001b[0m:      \t            (10, 0.3237246572971344)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simulação concluída.\n"
          ]
        }
      ],
      "source": [
        "def client_fn(context: Context):\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "    cid = int(context.node_id)% config.num_clients\n",
        "    client_id = int(cid)\n",
        "    train_idx = parts_train[client_id]\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    return AlzheimerClient(\n",
        "        cid=cid,\n",
        "        full_dataset=full_dataset,\n",
        "        train_idx=train_idx,\n",
        "        test_idx=idx_test,\n",
        "        num_classes=num_classes,\n",
        "        lr=config.learning_rate,\n",
        "        batch_size=config.batch_size,\n",
        "        local_epochs=config.local_epochs,\n",
        "        device=device\n",
        "    ).to_client()\n",
        "\n",
        "client_app = ClientApp(client_fn)\n",
        "\n",
        "def get_evaluate_fn():\n",
        "    _, test_tf = build_transforms()\n",
        "    test_dataset = TransformingSubset(Subset(full_dataset, idx_test), test_tf)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False,\n",
        "                             num_workers=0, persistent_workers=False, pin_memory=False)\n",
        "    def evaluate(server_round: int, parameters: NDArrays, _config: Dict[str, float]):\n",
        "        device = torch.device(\"cpu\")\n",
        "        model = build_model(num_classes).to(device)\n",
        "        set_params(model, parameters)\n",
        "        m = evaluate_model(model, test_loader, device, num_classes)\n",
        "        return m.loss, {\"accuracy\": m.accuracy, \"precision\": m.precision, \"recall\": m.recall, \"f1\": m.f1, \"auc\": m.auc}\n",
        "    return evaluate\n",
        "\n",
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    initial_parameters = ndarrays_to_parameters(get_params(build_model(num_classes)))\n",
        "    strategy = FedAvgM(\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=config.num_clients,\n",
        "        min_evaluate_clients=config.num_clients,\n",
        "        min_available_clients=config.num_clients,\n",
        "        evaluate_fn=get_evaluate_fn(),\n",
        "        on_fit_config_fn=lambda r: {\"local_epochs\": config.local_epochs},\n",
        "        evaluate_metrics_aggregation_fn=weighted_average,\n",
        "        server_learning_rate=config.server_learning_rate,\n",
        "        server_momentum=config.server_momentum,\n",
        "        initial_parameters=initial_parameters,\n",
        "    )\n",
        "    return ServerAppComponents(\n",
        "        strategy=strategy,\n",
        "        config=ServerConfig(num_rounds=config.num_rounds),\n",
        "    )\n",
        "\n",
        "server_app = ServerApp(server_fn=server_fn)\n",
        "print(\"Apps prontos. Iniciando simulação...\")\n",
        "\n",
        "history = run_simulation(\n",
        "    server_app=server_app,\n",
        "    client_app=client_app,\n",
        "    num_supernodes=config.num_clients,\n",
        "    backend_config={\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}},\n",
        ")\n",
        "\n",
        "print(\"Simulação concluída.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1fV75GSKRUlSbbogVsZBtx3SA_hLUQVPz",
      "authorship_tag": "ABX9TyMZThXDHjVhtbX6HptDDwM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}